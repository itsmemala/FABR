-------------------------------------------NoL1InLA (6 tasks)-----------------------------------------
-------------------------------IntentSH-EWC, lambda=max (rand 0,3,6)------------------------------------------
## Adapt-Zero ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type zero --save_wd_old_magn True --save_alpharel True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptZero.max/

## Adapt-KTEasy ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type kt_easy --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTEasy.max/

## Adapt-KT ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type kt --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKT.max/

## Adapt-KTCFscaledv1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv1 --ktcf_wgt_use_arel True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv1.max.1/
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv1 --ktcf_wgt 0.05 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv1.max.2/

## Adapt-KTCFscaledv2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv2 --ktcf_wgt_use_arel True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv2.max.1/
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv2 --ktcf_wgt 0.05 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv2.max.2/

## Adapt-KTCFscaledv3
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv3 --ktcf_wgt_use_arel True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv3.max.1/
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv3 --ktcf_wgt 0.05 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv3.max.2/

## Adapt-KTStrictv2 ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type kt_strictv2 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTStrictv2.max/

## Adapt-KTStrict ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type kt_strict --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTStrict.max/

## Adapt-KTStrictv3 ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type kt_strictv3 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTStrictv3.max/

## Adapt-One ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type one --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptOne.max/

## ANCL ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_ancl --backbone bert_adapter --baseline ewc_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --alpha_lamb 5000000 --ancl True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLEWC_wlast.max.1/

## LWF-ANCL ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_lwf --backbone bert_adapter --baseline lwf --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 0.1 --lwf True --lwf_T 2 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_LWF_wlast.1/
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_lwf_ancl --backbone bert_adapter --baseline lwf_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 1 --fisher_combine max --alpha_lamb 1 --lwf_ancl True --lwf_T 2 --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLLWF_wlast.1/
## CHSF ANCL LWF ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_lwf --backbone bert_adapter --baseline lwf --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --custom_lamb 0,0 --lwf True --lwf_T 2 --break_after_task 1 --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_LWF_wlast_t1gold/

## EWC (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_lamb_max True --fisher_combine max --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWCMax_wlast.max/

-------------------------------IntentSH-EWC, lambda=ind_max (rand 0,3,6)------------------------------------------
## EWC (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_ind_lamb_max True --fisher_combine max --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWCMax_wlast.ind_max.1/
(2 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_ind_lamb_max True --lamb_div 10 --fisher_combine max --modify_fisher_last True --save_wd_old_magn True --break_after_task 1 --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWCMax_wlast_2tasks.ind_max.2/
(Fisher Avg)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_ind_lamb_max True --lamb_div 800 --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWC_wlast.ind_max.8/


## Adapt-Zero ##
(2 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_ind_lamb_max True --lamb_div 10 --fisher_combine max --modify_fisher_last True --adapt_type zero --save_wd_old_magn True --save_alpharel True --break_after_task 1 --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptZero_2tasks.ind_max.2/

## Adapt-KTCFscaledv2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_freeze --backbone bert_adapter --baseline ewc_freeze --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --use_ind_lamb_max True --fisher_combine max --modify_fisher_last True --adapt_type ktcf_scaledv2 --ktcf_wgt_use_arel True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_NoL1LAEWC_wlast_AdaptKTCFsv2.ind_max.1/
-------------------------------IntentSH-EWC, lambda=50 x 10^5 (rand 0)------------------------------------------
## EWC (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 5000000 --fisher_combine max --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWCMax_wlast.4/
(Fisher Avg)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 5000000 --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWC_wlast.4/

## ANCL (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_ancl --backbone bert_adapter --baseline ewc_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 5000000 --fisher_combine max --alpha_lamb 5000000 --ancl True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLEWCMax_wlast.4.1/
(Fisher Avg)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_ancl --backbone bert_adapter --baseline ewc_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 5000000 --alpha_lamb 5000000 --ancl True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLEWC_wlast.4.1/
-------------------------------IntentSH-EWC, lambda=100 x 10^5 (rand 0)------------------------------------------
## EWC (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 10000000 --fisher_combine max --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWCMax_wlast.5/
(Fisher Avg)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 10000000 --modify_fisher_last True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_EWC_wlast.5/

## ANCL (Fisher Max) ##
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_ancl --backbone bert_adapter --baseline ewc_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 10000000 --fisher_combine max --alpha_lamb 5000000 --ancl True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLEWCMax_wlast.5.1/
(Fisher Avg)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc_ancl --backbone bert_adapter --baseline ewc_ancl --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 10000000 --alpha_lamb 5000000 --ancl True --save_wd_old_magn True --my_save_path /content/gdrive/MyDrive/Collas24/IntentSH_ANCLEWC_wlast.5.1/
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SyFsahFwRl-9"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from IPython.core.display import display, HTML\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9yCaJRfRp8q",
        "outputId": "647a8ca0-4180-4c2e-8171-598b2f7c5165"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = '/content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIMHAnalysis-MAS.1Freeze-v17.2.1/'"
      ],
      "metadata": {
        "id": "U2DDJawiRxgs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drug - Test data"
      ],
      "metadata": {
        "id": "1KVz3DuSS55h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att_ind = [(2,2),(3,2)]"
      ],
      "metadata": {
        "id": "K6J3NOAOSk3d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens={}\n",
        "i=att_ind[0][1]\n",
        "with open(root_folder+\"random0_seed0_inputtokens_task\"+str(i)+\"_test.txt\", \"rb\") as filename:\n",
        "    tokens[str(i)] = pickle.load(filename)\n",
        "len(tokens[str(i)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ABHzodtS_tk",
        "outputId": "2c0b93a5-9279-49b1-f8d7-6b540e1d24b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = {}\n",
        "predictions = {}\n",
        "attributions = {}\n",
        "for i,j in att_ind:\n",
        "    print(i,j)\n",
        "    path = os.path.join(root_folder+'random0_seed0_testattributions_model'+str(i)+'task'+str(j)+'.npz')\n",
        "    data = np.load(path)\n",
        "    targets[str(i)+str(j)] = data['targets']\n",
        "    predictions[str(i)+str(j)] = data['predictions']\n",
        "    attributions[str(i)+str(j)] = np.round(data['attributions'], 5)\n",
        "attributions[str(i)+str(j)].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh-fNGtYTjq8",
        "outputId": "043b07de-5b0c-482d-9e68-152c253f097d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "3 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58, 128, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='22'\n",
        "b='32'\n",
        "for i in range(len(tokens['2'])):\n",
        "    if predictions['22'][i] != predictions['32'][i]:\n",
        "        print(i,targets['22'][i],tokens['2'][i],predictions['22'][i],predictions['32'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWnvOgDRUPcX",
        "outputId": "4e9118e5-3fc1-4b75-b535-70f3ddb31ffe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 2 ['-', 'felt', 'a', 'bit', 'weird', '.'] 2 0\n",
            "33 2 ['what', ',', 'like', 'suicidal', '?'] 2 1\n",
            "50 2 ['no', 'one', 'wants', 'to', 'help', 'me', '.'] 2 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(targets['22'],predictions['22'],average='macro'))\n",
        "print(f1_score(targets['32'],predictions['32'],average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUj4KvsTVf3V",
        "outputId": "970b8b2f-7664-4995-b235-7d1e8b436383"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6621207687054921\n",
            "0.6203703703703703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drug - Train data"
      ],
      "metadata": {
        "id": "IvpBuAUnXZDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att_ind = [(2,2),(3,2)]"
      ],
      "metadata": {
        "id": "02OVAgEYXa3B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens={}\n",
        "i=att_ind[0][1]\n",
        "with open(root_folder+\"random0_seed0_inputtokens_task\"+str(i)+\".txt\", \"rb\") as filename:\n",
        "    tokens[str(i)] = pickle.load(filename)\n",
        "len(tokens[str(i)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTKwPx9fXcy7",
        "outputId": "a3775592-b59a-4c06-a00b-465b8f127f8b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "207"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = {}\n",
        "predictions = {}\n",
        "attributions = {}\n",
        "for i,j in att_ind:\n",
        "    print(i,j)\n",
        "    path = os.path.join(root_folder+'random0_seed0_attributions_model'+str(i)+'task'+str(j)+'.npz')\n",
        "    data = np.load(path)\n",
        "    targets[str(i)+str(j)] = data['targets']\n",
        "    predictions[str(i)+str(j)] = data['predictions']\n",
        "    attributions[str(i)+str(j)] = np.round(data['attributions'], 5)\n",
        "attributions[str(i)+str(j)].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UGa7pz_XhOT",
        "outputId": "b775f2f2-16bf-41c2-b590-dfa461014a74"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "3 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207, 128, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a='22'\n",
        "b='32'\n",
        "for i in range(len(tokens['2'])):\n",
        "    if predictions['22'][i] != predictions['32'][i]:\n",
        "        print(i,targets['22'][i],tokens['2'][i],predictions['22'][i],predictions['32'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlTcXwxBXmPT",
        "outputId": "3a8ba832-d1ee-400a-dda8-e94ed47ade00"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 2 ['no', 'one', 'wants', 'to', 'help', 'me', '.'] 2 0\n",
            "59 2 ['uh', ',', 'maybe', '.', 'maybe', 'it', \"'\", 's', 'just', 'my', 'general', 'sort', 'of', 'state', '.', 'um', ',', 'i', 'dunn', '##o', ',', 'sometimes', 'i', 'suppose', 'just', 'kind', 'of', 'weighs', 'on', 'my', 'mind', 'a', 'little', 'bit', 'like', ',', '\"', 'what', 'am', 'i', 'doing', 'or', 'why', 'am', 'i', 'spending', 'my', 'money', 'on', 'this', '?', '\"', 'i', 'mean', ',', 'when', 'it', \"'\", 's', 'happening', ',', 'it', \"'\", 's', 'like', ',', 'this', 'is', 'amazing', '.'] 2 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def highlighter(word,attr,check_attr1):\n",
        "    colors = [\"#FF3333\", \"#DD9999\", \"#9999DD\", '#3333FF'] # red red blue blue\n",
        "    if attr>=check_attr1:\n",
        "        color = colors[2]\n",
        "        word = '<span style=\"background-color:' +color+ '\">' +word+ '</span>'\n",
        "    return word"
      ],
      "metadata": {
        "id": "3O6sJmtrYTzF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=59\n",
        "temp_attributions = np.sum(attributions['22'][ind], 1)\n",
        "temp_attributions = temp_attributions[1:len(tokens['2'][ind])+1]\n",
        "token_attr = temp_attributions\n",
        "check_attr1=0\n",
        "text = ' '.join([highlighter(word,attr,check_attr1) for word,attr in zip(tokens['2'][ind],token_attr)])\n",
        "display(HTML(text))\n",
        "print(token_attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "UbvrOmboYELM",
        "outputId": "ef668f5b-06f5-4b47-e397-145d5ae3a5d9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:#9999DD\">uh</span> , <span style=\"background-color:#9999DD\">maybe</span> . <span style=\"background-color:#9999DD\">maybe</span> it ' s just <span style=\"background-color:#9999DD\">my</span> general sort <span style=\"background-color:#9999DD\">of</span> <span style=\"background-color:#9999DD\">state</span> <span style=\"background-color:#9999DD\">.</span> um <span style=\"background-color:#9999DD\">,</span> <span style=\"background-color:#9999DD\">i</span> <span style=\"background-color:#9999DD\">dunn</span> ##o <span style=\"background-color:#9999DD\">,</span> sometimes <span style=\"background-color:#9999DD\">i</span> suppose <span style=\"background-color:#9999DD\">just</span> kind of <span style=\"background-color:#9999DD\">weighs</span> on my mind <span style=\"background-color:#9999DD\">a</span> little bit <span style=\"background-color:#9999DD\">like</span> <span style=\"background-color:#9999DD\">,</span> \" <span style=\"background-color:#9999DD\">what</span> <span style=\"background-color:#9999DD\">am</span> i <span style=\"background-color:#9999DD\">doing</span> <span style=\"background-color:#9999DD\">or</span> why <span style=\"background-color:#9999DD\">am</span> i <span style=\"background-color:#9999DD\">spending</span> my <span style=\"background-color:#9999DD\">money</span> on <span style=\"background-color:#9999DD\">this</span> <span style=\"background-color:#9999DD\">?</span> <span style=\"background-color:#9999DD\">\"</span> <span style=\"background-color:#9999DD\">i</span> mean <span style=\"background-color:#9999DD\">,</span> <span style=\"background-color:#9999DD\">when</span> it ' s <span style=\"background-color:#9999DD\">happening</span> , it ' s <span style=\"background-color:#9999DD\">like</span> , this is <span style=\"background-color:#9999DD\">amazing</span> ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.11207 -0.09832  0.12654 -0.04824  0.01112 -0.04904 -0.00845 -0.04626\n",
            " -0.02129  0.02648 -0.06711 -0.21684  0.13114  0.19767  0.0632  -0.0355\n",
            "  0.00743  0.09335  0.25885 -0.0962   0.00106 -0.03065  0.034   -0.09089\n",
            "  0.02953 -0.00039 -0.00329  0.14362 -0.0187  -0.02325 -0.00115  0.0231\n",
            " -0.01658 -0.00456  0.0039   0.03781 -0.03778  0.07194  0.02154 -0.03206\n",
            "  0.06318  0.02615 -0.03242  0.07175 -0.03071  0.03187 -0.00805  0.13388\n",
            " -0.05124  0.03862  0.00507  0.05181  0.13332 -0.11915  0.00302  0.10291\n",
            " -0.03295 -0.00802 -0.06565  0.11393 -0.05238 -0.02906 -0.03289 -0.13586\n",
            "  0.14968 -0.08512 -0.03057 -0.02601  0.37472 -0.05162]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind=59\n",
        "temp_attributions = np.sum(attributions['32'][ind], 1)\n",
        "temp_attributions = temp_attributions[1:len(tokens['2'][ind])+1]\n",
        "token_attr = temp_attributions\n",
        "check_attr1=0\n",
        "text = ' '.join([highlighter(word,attr,check_attr1) for word,attr in zip(tokens['2'][ind],token_attr)])\n",
        "display(HTML(text))\n",
        "print(token_attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "wPm8XEs2Zm3Z",
        "outputId": "17c0c3ef-ab50-438a-bf75-490c31b954dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:#9999DD\">uh</span> , <span style=\"background-color:#9999DD\">maybe</span> . maybe it ' s just my general sort <span style=\"background-color:#9999DD\">of</span> <span style=\"background-color:#9999DD\">state</span> <span style=\"background-color:#9999DD\">.</span> um , <span style=\"background-color:#9999DD\">i</span> <span style=\"background-color:#9999DD\">dunn</span> ##o , sometimes i <span style=\"background-color:#9999DD\">suppose</span> <span style=\"background-color:#9999DD\">just</span> kind of <span style=\"background-color:#9999DD\">weighs</span> on my mind <span style=\"background-color:#9999DD\">a</span> little <span style=\"background-color:#9999DD\">bit</span> like <span style=\"background-color:#9999DD\">,</span> \" <span style=\"background-color:#9999DD\">what</span> <span style=\"background-color:#9999DD\">am</span> i <span style=\"background-color:#9999DD\">doing</span> <span style=\"background-color:#9999DD\">or</span> why <span style=\"background-color:#9999DD\">am</span> i <span style=\"background-color:#9999DD\">spending</span> my <span style=\"background-color:#9999DD\">money</span> on <span style=\"background-color:#9999DD\">this</span> <span style=\"background-color:#9999DD\">?</span> <span style=\"background-color:#9999DD\">\"</span> <span style=\"background-color:#9999DD\">i</span> mean , <span style=\"background-color:#9999DD\">when</span> it ' s <span style=\"background-color:#9999DD\">happening</span> , it ' s <span style=\"background-color:#9999DD\">like</span> , this is <span style=\"background-color:#9999DD\">amazing</span> ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.06261 -0.09491  0.09385 -0.07317 -0.01575 -0.04803 -0.01139 -0.05019\n",
            " -0.02627 -0.00795 -0.06502 -0.15247  0.08352  0.0867   0.0392  -0.02872\n",
            " -0.00659  0.04842  0.09442 -0.09599 -0.01279 -0.00683 -0.01034  0.00632\n",
            "  0.01026 -0.0046  -0.02232  0.07247 -0.027   -0.03952 -0.00455  0.01364\n",
            " -0.02642  0.00274 -0.01955  0.01338 -0.01088  0.05869  0.02037 -0.02958\n",
            "  0.03887  0.02455 -0.01685  0.06477 -0.03034  0.02237 -0.01872  0.07211\n",
            " -0.01978  0.02245  0.00915  0.05567  0.06934 -0.09867 -0.00654  0.06452\n",
            " -0.04678 -0.0092  -0.07932  0.08585 -0.05002 -0.05862 -0.02335 -0.13136\n",
            "  0.12122 -0.07859 -0.03828 -0.03077  0.2214  -0.0505 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise - Train LA"
      ],
      "metadata": {
        "id": "107lhTr2h4L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=3\n",
        "with open(root_folder+\"random0_seed0_inputtokens_task\"+str(i)+\".txt\", \"rb\") as filename:\n",
        "    tokens[str(i)] = pickle.load(filename)\n",
        "len(tokens[str(i)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUIwAXSyh-TU",
        "outputId": "295f7595-bc3d-43c0-f749-47e6ab6e5a7d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "304"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = {}\n",
        "predictions = {}\n",
        "attributions = {}\n",
        "i,j = 3,3\n",
        "path = os.path.join(root_folder+'random0_seed0_attributions_model'+str(i)+'task'+str(j)+'_lastart.npz')\n",
        "data = np.load(path)\n",
        "targets['lastart'] = data['targets']\n",
        "predictions['lastart'] = data['predictions']\n",
        "attributions['lastart'] = np.round(data['attributions'], 5)\n",
        "path = os.path.join(root_folder+'random0_seed0_attributions_model'+str(i)+'task'+str(j)+'_laend.npz')\n",
        "data = np.load(path)\n",
        "targets['laend'] = data['targets']\n",
        "predictions['laend'] = data['predictions']\n",
        "attributions['laend'] = np.round(data['attributions'], 5)\n",
        "attributions['laend'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ipc9ArZiKgi",
        "outputId": "25ce91ec-2b54-45dc-d64d-84841a24d0e2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(304, 128, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokens['3'])):\n",
        "    if predictions['lastart'][i] != predictions['laend'][i]:\n",
        "        print(i,targets['lastart'][i],tokens['3'][i],predictions['lastart'][i],predictions['laend'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVulx8W-iwj9",
        "outputId": "a5d0d6a2-8694-4c7b-e166-a29084dfcdd6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 ['yeah', '.'] 1 0\n",
            "5 2 ['um', ',', 'i', 'do', 'feel', 'better', '.'] 1 0\n",
            "6 2 ['yeah', ',', 'i', \"'\", 've', 'got', 'other', 'things', 'to', 'do', '.', 'i', \"'\", 've', 'got', 'accounts', 'to', 'do', '.'] 2 1\n",
            "7 0 ['plus', 'there', \"'\", 's', 'people', 'who', 'have', 'done', 'that', 'countless', 'times', 'and', 'you', 'can', 'go', 'read', 'what', 'their', '-'] 2 0\n",
            "8 2 ['it', '-', 'it', '-', 'it', 'would', 'be', 'important', '.'] 1 0\n",
            "9 0 ['yeah', ',', 'i', 'do', 'head', '##phones', '.'] 1 2\n",
            "11 2 ['well', ',', 'um', '.', 'i', '-', 'i', 'didn', \"'\", 't', 'get', '-', 'go', 'to', 'physical', 'therapy', 'this', 'week', ',', 'and', 'the', '-', 'or', 'tai', 'chi', ',', 'actually', '.'] 2 0\n",
            "13 1 ['yeah', ',', 'i', 'mean', ',', 'i', ',', 'to', 'a', 'certain', 'extent', ',', 'because', 'of', 'my', 'lifestyle', ',', 'food', 'is', 'just', 'fuel', '.'] 1 0\n",
            "15 2 ['-', 'and', 'b', ',', 'if', 'i', 'can', 'make', 'an', 'appointment', '-'] 1 2\n",
            "17 2 ['well', ',', 'i', 'don', \"'\", 't', 'see', 'how', 'i', 'could', 'do', 'it', '.', 'i', '-', 'i', \"'\", 'm', 'still', 'in', 'a', 'walker', ',', 'you', 'know', '.'] 1 2\n",
            "18 0 ['i', \"'\", 'll', 'really', 'fall', 'and', 'hurt', 'myself', ',', 'and', 'this', 'way', ',', 'if', 'i', 'don', \"'\", 't', 'move', 'around', 'so', 'much', ',', 'there', \"'\", 's', 'less', 'chance', 'that', 'i', 'will', '.'] 1 2\n",
            "22 0 ['-', 'means', 'that', 'i', 'have', 'to', 'work', 'in', 'the', 'evening', '-'] 1 2\n",
            "23 2 ['you', 'know', '?', 'um', ',', 'because', 'i', \"'\", 'm', 'jug', '##gling', 'all', 'these', 'balls', ',', 'and', 'i', 'don', \"'\", 't', 'want', 'to', 'drop', 'any', '.'] 2 1\n",
            "24 0 ['yeah', '.'] 1 2\n",
            "26 0 ['okay', '.', 'okay', '.', 'okay', '.', 'i', '-', 'i', \"'\", 'm', 'willing', 'to', 'start', 'again', ',', 'so', 'to', 'speak', '.'] 2 0\n",
            "28 2 ['yeah', '.'] 2 0\n",
            "30 1 ['i', \"'\", 've', 'got', 'clients', 'they', \"'\", 're', 'coming', 'in', '.'] 1 2\n",
            "33 0 ['i', \"'\", 've', 'got', 'a', 'pile', 'of', 'work', '-'] 1 2\n",
            "34 2 ['like', 'i', 'don', \"'\", 't', 'wanna', 'go', 'back', 'to', 'the', 'hospital', ',', 'right', '?', 'i', 'really', 'don', \"'\", 't', '.', 'do', 'i', 'have', 'to', '?'] 2 1\n",
            "36 0 ['obviously', ',', 'i', 'need', 'to', 'cut', 'back', 'on', 'the', 'fruit', 'juice', '.', 'but', 'boy', ',', 'do', 'i', 'love', 'that', 'o', '##j', '.'] 2 0\n",
            "37 0 ['mm', '-', 'hmm', '.'] 2 1\n",
            "38 2 ['i', 'just', 'need', 'to', 'find', 'the', 'time', 'to', 'do', 'it', '.', 'and', ',', 'yes', ',', 'i', 'might', 'be', 'lacking', 'a', 'little', 'bit', 'of', 'motivation', ',', 'but', 'i', 'think', 'it', \"'\", 's', 'more', 'timing', 'and', 'trying', 'to', 'fit', 'it', 'in', '.'] 2 0\n",
            "39 0 ['okay', '.', 'very', 'good', '.', 'thanks', '.'] 1 0\n",
            "40 1 ['i', 'think', 'the', 'activity', 'piece', 'is', 'the', 'kind', 'of', 'low', '-', 'hanging', 'fruit', 'that', 'i', 'see', '.', 'um', ',', 'i', 'feel', 'like', 'it', \"'\", 's', 'gonna', 'be', 'harder', 'for', 'me', 'to', 'change', 'some', 'of', 'my', 'nutrition', 'habits', 'right', 'out', 'the', 'gate', ',', 'but', 'if', 'i', 'can', 'get', 'into', 'maybe', 'an', 'activity', 'routine', ',', 'that', 'that', 'could', 'be', 'good', 'to', 'help', 'maybe', 'some', 'of', 'the', 'other', 'changes', 'happen', 'later', '.'] 2 1\n",
            "41 0 ['yeah', ',', 'no', ',', 'yeah', '.', 'that', \"'\", 's', 'a', 'good', '-', 'good', 'recommendation', '.', 'i', \"'\", 'll', 'definitely', 'check', 'it', 'out', '.'] 1 2\n",
            "42 0 ['okay', ',', 'okay', '.'] 2 0\n",
            "43 0 ['right', '.', 'yeah', '.'] 1 0\n",
            "44 2 ['that', \"'\", 's', 'a', 'strong', 'word', ',', 'isn', \"'\", 't', 'it', ',', '\"', 'betrayed', '\"', '.', 'um', ',', 'wow', '.', 'a', 'little', ',', 'but', '-', 'but', 'i', '-', 'i', 'know', ',', 'i', 'know', 'that', 'it', \"'\", 's', 'true', '.', 'i', 'mean', ',', 'my', 'friend', 'who', 'does', 'tai', 'chi', ',', 'she', 'just', '-', 'she', 'loves', 'it', '.', 'maybe', 'it', \"'\", 's', 'just', 'not', 'for', 'me', ',', 'you', 'know', '.'] 2 0\n",
            "45 0 ['so', ',', 'um', ',', 'i', 'do', 'think', 'that', 'that', 'would', 'be', 'an', 'option', '.', 'um', ',', 'i', 'did', 'enjoy', 'doing', 'yoga', 'in', 'the', 'past', '.', 'i', ',', 'um', ',', 'i', 'don', \"'\", 't', 'care', 'for', 'swimming', ',', 'uh', ',', 'because', 'it', 'requires', 'a', 'lot', 'of', 'extra', 'prep', 'time', ',', 'and', 'like', ',', 'i', 'don', \"'\", 't', '-', 'ch', '##lor', '##ine', 'in', 'my', 'hair', 'just', 'doesn', \"'\", 't', 'really', 'go', 'very', 'well', 'usually', '.', 'um', ',', 'but', 'i', 'really', 'like', 'walking', ',', 'um', ',', 'weightlifting', ',', 'running', 'is', 'okay', '.', 'um', ',', 'that', 'was', 'more', 'at', 'my', ',', 'like', ',', 'peak', 'activity', 'level', ',', 'so', 'i', 'don', \"'\", 't', 'think', 'i', 'could', 'start', 'out', 'running', 'now', ',', 'but', 'i', \"'\", 'd', 'like', 'to', 'work', 'up', 'to', 'it'] 1 0\n",
            "49 1 ['uh', ',', 'well', ',', 'i', \"'\", 'm', 'glad', 'to', 'see', 'my', 'dog', ',', 'he', \"'\", 's', 'very', 'cute', ',', 'and', 'it', 'just', 'feels', 'good', 'to', 'be', 'home', '.'] 1 0\n",
            "54 2 ['sure', '.', 'yeah', '.'] 2 1\n",
            "58 2 ['yeah', '.'] 2 0\n",
            "60 2 ['thank', 'you', '.', 'thank', 'you', '.'] 2 0\n",
            "62 0 ['yeah', '.'] 2 0\n",
            "64 2 ['-', 'ever', 'since', 'i', 'started', 'becoming', 'conscious', 'of', 'my', 'body', '.'] 0 2\n",
            "65 0 ['yeah', ',', 'yeah', ',', 'i', 'think', 'so', '.', 'um', ',', 'that', \"'\", 's', 'not', 'to', 'say', 'like', ',', 'i', 'wanna', 'go', 'run', 'a', 'marathon', 'but', 'i', 'do', 'think', 'that', 'it', 'would', 'help', 'me', 'a', 'lot', 'in', 'terms', 'of', 'just', 'having', 'a', 'better', 'outlook', 'on', 'life', ',', 'um', ',', 'and', 'better', 'energy', 'to', '-', 'if', 'i', 'were', 'to', 'pick', 'up', 'some', 'type', 'of', 'activity', '.'] 2 0\n",
            "69 2 ['okay', '.'] 1 2\n",
            "70 0 ['my', 'back', '—'] 2 1\n",
            "71 1 ['-', 'you', 'know', ',', 'and', 'then', 'as', 'i', \"'\", 'm', 'looking', 'at', 'that', 'double', 'or', 'triple', 'fu', '##dge', 'four', '-', 'decker', 'of', 'ice', 'cream', 'sunday', 'thing', ',', 'you', 'know', ',', 'that', 'somebody', 'is', 'eating', ',', 'i', 'would', 'say', ',', '\"', 'wow', ',', 'that', 'would', 'be', 'about', 'two', 'hours', 'on', 'the', 'tread', '##mill', '.', '\"', 'then', '-', 'then', 'that', 'would', 'be', 'probably', '-', '-', 'the', '-', '-', 'that', 'would', 'keep', 'me', 'from', 'actually', 'ordering', 'one', 'of', 'those', '.'] 1 2\n",
            "72 0 ['yeah', '.'] 2 1\n",
            "74 0 ['mm', '-', 'hmm', '.'] 1 2\n",
            "76 2 ['hi', '.'] 1 0\n",
            "77 2 ['well', ',', 'my', 'back', 'doesn', \"'\", 't', 'hurt', 'nearly', 'so', 'much', '.'] 1 2\n",
            "81 0 ['absolutely', '.', 'i', 'do', 'not', 'want', 'to', 'fall', ',', 'for', 'sure', '.'] 1 0\n",
            "82 0 ['that', 'i', 'will', 'definitely', '-', 'i', 'definitely', 'wanna', 'do', 'that', '.'] 1 2\n",
            "83 2 ['well', ',', 'i', 'think', ',', 'uh', ',', 'when', 'i', 'really', 'start', 'seeing', 'some', 'results', 'at', 'the', 'gym', ',', 'it', \"'\", 's', 'kinda', ',', 'uh', ',', 'i', 'think', 'the', 'way', 'it', 'works', 'in', 'my', 'mind', 'is', 'if', 'i', \"'\", 've', 'worked', 'out', 'really', 'hard', 'and', 'i', \"'\", 've', '-', 'and', 'i', \"'\", 've', '-', '-', 'say', 'i', \"'\", 've', 'lost', 'a', 'pound', 'that', 'week', '-'] 1 2\n",
            "84 0 ['well', ',', 'doc', ',', 'i', 'know', 'you', 'told', 'me', 'that', 'i', 'need', 'to', 'lose', 'weight', '.', 'and', 'even', 'though', 'the', 'scale', 'didn', \"'\", 't', 'show', 'today', ',', 'i', 'was', 'able', 'to', 'lose', 'about', '5', 'pounds', ',', 'but', 'then', 'i', 'gained', 'it', 'right', 'back', '.'] 0 2\n",
            "86 2 ['-', 'i', 'expect', 'them', 'to', 'start', 'at', '10', ':', '00', ',', 'not', '10', ':', '45', '.'] 2 0\n",
            "87 0 ['um', ',', 'six', 'or', 'seven', '.'] 1 2\n",
            "88 0 ['i', 'wanna', 'go', 'home', '.'] 1 0\n",
            "90 0 ['mm', '-', 'hmm', '.'] 2 0\n",
            "91 2 ['um', ',', 'when', 'you', 'talk', 'about', 'activity', 'and', 'you', 'mentioned', 'like', 'really', ',', 'um', ',', 'like', 'rigorous', 'activity', 'types', ',', 'um', ',', 'like', 'i', 'go', 'to', 'a', 'gym', 'and', 'i', 'enjoy', 'going', 'to', 'the', 'gym', 'when', 'i', 'was', 'active', '.'] 2 1\n",
            "92 2 ['like', 'last', 'week', ',', 'i', '-', 'i', 'didn', \"'\", 't', 'get', 'there', 'at', 'all', 'until', 'like', 'thursday', 'during', 'the', 'week', ',', '-'] 2 0\n",
            "93 0 ['and', 'then', 'i', '-', '-', '[', 'un', '##int', '##elli', '##gible', '00', ':', '04', ':', '41', ']', 'kinda', 'nice', '[', 'un', '##int', '##elli', '##gible', '00', ':', '4', ':', '42', ']', 'gonna', 'be', 'troubles', '##ome', '.'] 1 0\n",
            "94 0 ['and', 'i', '-', '-', 'and', 'really', ',', 'it', \"'\", 's', 'kind', 'of', 'an', 'excuse', ',', 'i', 'guess', ',', 'cause', 'i', '-', 'i', 'could', 'probably', 'make', 'the', 'time', ',', 'but', 'it', \"'\", 's', '-', 'it', \"'\", 's', 'easier', 'to', 'just', 'keep', 'working', 'or', '-'] 1 0\n",
            "95 2 ['um', ',', 'yeah', ',', 'i', 'mean', ',', 'who', 'doesn', \"'\", 't', '?', 'i', 'mean', ',', 'i', \"'\", 'm', 'aware', 'that', 'i', \"'\", 'm', 'over', 'my', ',', 'uh', ',', 'uh', ',', 'b', '-', 'b', '-', 'b', '-', 'balance', 'weight', ',', 'but', 'i', 'now', 'know', 'that', 'it', \"'\", 's', 'causing', 'problems', '.', 'i', 'mean', ',', 'obviously', ',', 'i', 'get', 'out', 'of', 'breath', 'if', 'i', 'have', 'to', 'do', 'something', 'a', 'bit', 'howe', '##ring', ',', 'and', 'i', 'realize', 'that', 'i', \"'\", 'm', 'on', 'this', 'blood', 'pressure', '-'] 2 0\n",
            "96 2 ['mm', '-', 'hmm', '.'] 2 0\n",
            "97 2 ['uh', ',', 'i', 'have', '.'] 2 0\n",
            "100 2 ['yeah', ',', 'i', 'guess', 'so', '.'] 2 0\n",
            "102 2 ['yeah', '.', 'um', ',', 'i', \"'\", 'm', 'really', 'starting', 'to', 'notice', 'how', 'i', 'feel', 'more', 'slug', '##gis', '##h', 'and', 'just', 'not', '-', '-', 'my', 'mood', 'is', 'shifted', 'a', 'lot', 'too', ',', 'which', 'at', 'first', ',', 'i', 'thought', 'was', 'because', 'it', \"'\", 's', 'getting', 'colder', 'outside', ',', 'um', ',', 'but', 'i', 'do', 'also', 'think', 'it', 'maybe', 'has', 'some', 'relation', 'to', 'my', 'activity', ',', 'or', 'lack', 'thereof', ',', 'and', 'also', 'kind', 'of', 'the', 'foods', 'that', 'i', \"'\", 'm', 'eating', '.'] 1 0\n",
            "103 0 ['well', ',', 'yeah', ',', 'if', 'i', '-', 'if', 'i', 'lose', 'my', 'balance', 'and', 'fall', 'down', ',', 'i', 'could', '-', 'anything', ',', 'you', 'know', ',', 'really', 'get', 'hurt', ',', 'and', 'then', '-', 'then', 'i', 'wouldn', \"'\", 't', 'be', 'able', 'to', 'be', 'home', 'anymore', ',', 'and', 'that', \"'\", 's', 'not', 'what', 'i', 'want', '.', 'i', 'want', 'to', 'stay', 'home', '.', 'so', 'i', 'want', 'to', 'do', 'what', 'i', 'have', 'to', 'do', 'to', '-', 'to', '-', 'to', 'stay', 'home', '.'] 2 0\n",
            "104 2 ['wait', 'a', 'minute', ',', 'isn', \"'\", 't', 'walking', 'too', 'mild', 'to', 'help', 'you', 'lose', 'weight', ',', 'though', '?'] 2 0\n",
            "106 2 ['she', 'did', '.', 'sh', '-', '-', 'yeah', ',', 'that', \"'\", 's', 'right', ',', 'that', \"'\", 's', 'right', '.', 'she', 'said', 'that', 'they', 'did', 'studies', 'and', 'that', 'they', 'found', 'that', 'it', 'was', 'really', 'prevent', '##ative', '.', 'i', 'think', 'she', \"'\", 's', '-', 'i', 'forget', 'the', '-', 'the', 'percentage', ',', 'but', 'yeah', ',', 'she', 'was', 'really', 'enthusiastic', 'and', 'she', 'does', 'it', 'herself', '.'] 2 0\n",
            "107 2 ['yeah', ',', 'that', \"'\", 'd', 'be', 'great', '.'] 2 0\n",
            "108 0 ['-', 'i', 'know', 'that', '.', 'but', 'it', \"'\", 's', 'hard', 'getting', 'to', 'the', 'point', 'where', 'i', '-'] 1 0\n",
            "109 2 ['well', ',', 'i', 'just', 'can', \"'\", 't', 'seem', 'to', 'get', 'back', 'in', 'the', 'gym', '.', 'i', 'don', \"'\", 't', 'wanna', '-', '-', 'i', '-', 'i', 'used', 'to', 'work', 'out', 'quite', 'a', 'bit', ',', 'and', 'in', 'the', 'last', ',', 'i', 'dunn', '##o', ',', 'couple', 'of', 'years', 'i', \"'\", 've', 'just', '-', '-', 'i', 'stopped', 'going', '.', 'i', 'got', 'busy', ',', 'and', 'now', 'i', \"'\", 'm', 'out', 'of', 'the', 'habit', ',', 'and', 'i', '-', 'i', 'really', ',', 'i', 'dunn', '##o', ',', 'i', 'feel', 'like', 'i', 'need', 'to', 'get', 'back', '.'] 1 0\n",
            "110 0 ['i', 'was', 'kinda', 'busy', 'with', 'some', 'other', 'things', ',', 'but', ',', 'um', '—'] 2 0\n",
            "111 0 ['um', ',', 'i', 'really', 'want', 'to', 'start', 'working', 'out', 'again', '.', 'definitely', 'wanna', 'get', 'back', 'in', 'it', ',', 'have', 'a', 'routine', ',', 'and', 'just', 'be', 'healthy', '.'] 1 0\n",
            "113 2 ['thank', 'you', '.'] 1 0\n",
            "115 0 ['you', 'know', ',', 'so', 'i', 'think', 'the', 'just', 'running', 'off', 'the', 'play', '##list', '.', 'i', '-', 'i', 'guess', 'maybe', 'if', 'i', 'made', 'a', 'goal', 'would', 'helped', 'too', '.'] 1 2\n",
            "117 2 ['home', 'workout', '##s', 'have', 'never', 'really', 'worked', 'for', 'me', 'in', 'the', 'past', 'just', 'because', 'there', \"'\", 's', 'so', 'many', 'distraction', '##s', ',', 'and', 'i', 'can', ',', 'like', ',', 'set', 'the', 'mat', 'out', 'there', 'and', 'everything', 'and', 'get', 'everything', 'ready', ',', 'like', 'bottled', 'water', ',', 'everything', \"'\", 's', 'good', 'to', 'go', '.', 'and', 'then', 'it', 'just', 'sits', 'there', 'and', 'i', 'don', \"'\", 't', 'actually', 'do', 'it', ',', 'whereas', 'if', 'i', 'go', 'somewhere', 'else', ',', 'i', \"'\", 'm', 'already', 'there', '.', 'and', 'so', 'i', \"'\", 'm', 'doing', 'it', '.'] 1 2\n",
            "118 0 ['yeah', '.'] 1 0\n",
            "121 2 ['everything', '.', 'i', 'wanna', '-', 'i', 'wanna', ',', 'play', 'with', 'my', 'dog', '.', 'i', 'miss', 'my', 'dog', '.', 'i', 'wanna', 'cook', 'for', 'myself', '.', 'i', \"'\", 'm', 'a', 'very', 'independent', 'person', 'and', 'i', 'wanna', 'do', 'things', 'for', 'myself', '.'] 2 1\n",
            "122 0 ['yeah', ',', 'yeah', '.', 'food', 'on', 'the', 'run', ',', 'you', 'know', '?'] 1 0\n",
            "123 2 ['um', ',', 'well', ',', 'um', ',', 'i', 'like', '-', '-', 'the', 'bike', 'is', 'pretty', 'good', '.', 'uh', ',', 'even', 'the', 'uh', ',', 'you', 'know', ',', 'the', 'kind', 'of', 'a', 'rolling', 'machine', 'is', 'okay', '.', 'and', 'the', 'uh', ',', 'the', 'elliptical', '.', 'any', 'of', 'that', '’', 's', 'fine', '.', 'i', '-', 'i', 'really', 'don', '’', 't', ',', 'uh', '-', '-', 'i', 'don', '’', 't', 'dislike', 'any', 'of', 'it', '.', 'kind', 'of', 'once', 'you', 'get', 'into', 'the', 'rhythm', ',', 'yeah', ',', 'it', '’', 's', 'fine'] 2 0\n",
            "125 0 ['yeah', '.'] 1 2\n",
            "126 2 ['what', '?'] 2 0\n",
            "127 2 ['well', ',', 'i', '-', 'i', '-', 'i', '-', 'i', 'would', 'feel', 'better', '.', 'my', '-', '-', 'i', \"'\", 'd', '-', 'i', \"'\", 'd', 'be', 'able', 'to', 'wear', 'more', 'my', 'clothes', '.', 'i', \"'\", 've', 'been', 'growing', 'around', 'the', 'middle', 'and', 'i', \"'\", 'd', 'like', 'to', ',', 'uh', ',', 'you', 'know', ',', 'go', 'back', 'to', 'where', 'i', 'was', ',', 'you', 'know', ',', 'get', 'into', 'a', '34', ',', '36', 'waist', ',', 'you', 'know', '.'] 2 0\n",
            "128 0 ['yeah', '.', 'i', '-'] 1 2\n",
            "131 0 ['hmm', '.', 'and', 'i', 'know', 'my', 'family', 'would', 'support', 'me', 'if', 'i', 'could', 'just', 'find', 'some', 'place', 'where', 'i', 'can', 'go', 'dancing', '.'] 1 0\n",
            "136 2 ['yeah', '.'] 1 0\n",
            "137 2 ['but', 'i', 'want', 'to', 'be', 'like', '-', '-', 'i', 'don', \"'\", 't', 'want', 'to', 'be', 'like', 'stick', '-', 'thin', ',', 'but', 'i', 'really', 'want', 'to', 'be', 'like', 'really', 'healthy', 'and', 'really', 'active', '.'] 2 0\n",
            "143 0 ['yeah', '.'] 1 2\n",
            "144 2 ['i', 'can', 'do', 'anything', '-'] 2 0\n",
            "145 1 ['yeah', '.', 'um', ',', 'i', \"'\", 'm', 'glad', 'to', 'be', 'there', '.'] 1 2\n",
            "146 2 ['hmm', ',', 'i', \"'\", 'd', 'say', 'i', \"'\", 'm', 'about', 'an', 'eight', '.'] 2 0\n",
            "147 2 ['um', ',', 'i', 'guess', 'the', 'rehab', '.'] 2 1\n",
            "148 0 ['um', ',', 'well', ',', 'i', 'guess', 'just', 'sticking', 'with', 'it', 'and', 'not', 'getting', ',', 'um', ',', 'side', '##tra', '##cked', '.'] 1 2\n",
            "149 2 ['-', 'i', 'did', 'burn', 'for', 'a', 'time', '.'] 2 0\n",
            "151 0 ['with', 'me', ',', 'it', \"'\", 's', 'very', 'often', '—'] 0 2\n",
            "152 0 ['yeah', ',', 'and', 'you', 'know', 'what', '?', 'i', 'really', 'like', 'to', 'try', 'that', '.'] 2 0\n",
            "154 0 ['yeah', '.'] 1 2\n",
            "160 2 ['i', '-', 'i', \"'\", 'm', 'more', 'comfortable', '-', '-', 'i', 'feel', 'better', '.', 'i', 'think', 'that', \"'\", 's', 'the', 'main', 'thing', '.'] 2 0\n",
            "162 2 ['i', 'should', '-', '-', 'or', 'next', 'to', 'nothing', '.', 'i', 'walk', 'to', 'the', 'grocery', 'store', 'or', 'whatever', '’', 's', 'handy', 'when', 'i', 'have', 'time', ',', 'but', 'yeah', '.'] 2 0\n",
            "165 0 ['yeah', ',', 'i', 'mean', ',', 'okay', ',', 'fair', 'enough', ',', 'um', ',', 'i', \"'\", 've', 'got', 'to', 'have', 'my', 'blood', 'pressure', '-'] 1 0\n",
            "166 0 ['right', '.'] 1 2\n",
            "167 0 ['watch', 'the', 'tv', 'and', 'pet', 'my', 'dog', '.', 'i', '-', 'i', ',', 'you', 'know', ',', 'not', 'to', 'that', 'extreme', ',', 'but', 'yeah', ',', 'i', 'think', '-', 'i', 'think', 'maybe', ',', 'um', ',', 'yeah', ',', 'i', 'was', '-', 'was', 'going', '-', 'pushing', 'too', 'hard', '.'] 2 0\n",
            "168 0 ['yeah', '.', 'so', 'the', '-', 'the', 'case', '##work', '##er', 'is', 'gonna', 'be', 'able', 'to', 'come', 'and', 'ref', '##resh', '-'] 1 2\n",
            "171 2 ['very', 'good', '.'] 2 0\n",
            "174 2 ['i', 'let', '-', '-', 'i', 'lit', 'it', 'on', 'fire', 'but', 'i', '-'] 0 2\n",
            "177 2 ['oh', ',', 'yeah', '.'] 1 0\n",
            "179 0 ['yeah', '.'] 2 0\n",
            "180 2 ['-', 'just', 'being', 'in', 'bed', 'or', 'whatever', '.'] 2 0\n",
            "182 2 ['um', ',', 'i', 'don', '’', 't', 'know', '.', 'i', 'think', '-', 'i', 'think', 'the', 'time', 'has', 'just', 'been', 'the', 'biggest', 'thing', ',', 'you', 'know', ',', 'and', '-', 'and', 'i', '-', 'i', 'guess', 'the', 'motivation', 'really', 'hasn', '’', 't', 'been', 'there', '.', 'i', 'mean', ',', 'you', 'know', ',', 'it', '’', 's', 'not', 'like', '-', 'i', 'don', '’', 't', 'really', 'have', 'a', 'goal', '.', 'i', 'don', '’', 't', 'really', 'have', 'a', ',', 'you', 'know', 'i', 'don', \"'\", 't', ',', 'other', 'than', 'maybe', 'reducing', 'my', 'waist', '##line', ',', 'you', 'know', ',', 'i', 'don', \"'\", 't', 'really', 'have', 'a', '-', 'a', 'set', 'number', 'like', 'i', \"'\", 'm', 'gonna', 'run', 'a', 'marathon', 'and', 'you', 'know', '.'] 2 0\n",
            "185 2 ['well', ',', 'just', 'about', 'every', 'joint', 'like', 'especially', 'my', 'knees', '.', 'they', \"'\", 're', 'really', '-', '-', 'they', 'have', 'me', 'doing', 'some', 'leg', 'things', 'that', '-', 'that', '-', 'that', 'is', 'it', 'really', 'necessary', '?'] 2 0\n",
            "186 2 ['mm', '-', 'hmm', '.'] 2 0\n",
            "187 0 ['-', 'or', 'whatever', ',', \"'\", 'cause', 'it', \"'\", 's', '—'] 2 0\n",
            "188 2 ['if', 'i', 'make', 'an', 'appointment', 'with', 'a', 'client', 'for', '10', ':', '00', '-'] 2 0\n",
            "190 0 ['i', 'guess', '.'] 2 0\n",
            "192 2 ['not', 'ha', '-', '-', 'i', 'just', 'don', \"'\", 't', 'like', 'being', 'un', '##hea', '##lth', '##y', '.', 'it', 'doesn', \"'\", 't', 'make', 'me', 'feel', 'good', ',', 'so', 'i', \"'\", 'm', 'motivated', 'to', 'change', ',', 'it', \"'\", 's', 'just', 'getting', 'there', '.'] 2 1\n",
            "194 0 ['-', 'about', '-'] 2 0\n",
            "195 2 ['i', 'think', 'i', 'saw', 'something', 'like', 'that', 'on', 'tv', '.'] 2 0\n",
            "199 2 ['yeah', ',', 'but', 'hopefully', 'there', \"'\", 's', 'one', '.', 'so', ',', 'yeah', '.'] 2 0\n",
            "200 2 ['so', '—'] 2 0\n",
            "201 0 ['i', \"'\", 'm', 'aware', 'of', 'the', 'problems', ',', 'and', 'i', \"'\", 'm', 'also', 'aware', 'of', 'the', 'solutions', '.'] 1 0\n",
            "202 2 ['yes', '.'] 2 1\n",
            "203 2 ['so', 'if', 'i', '-', 'if', 'i', 'could', '-', '-', 'i', 'mean', ',', 'i', 'wanna', 'get', 'there', 'three', 'times', 'a', 'week', '.'] 2 0\n",
            "205 0 ['it', 'is', 'without', 'any', 'of', 'the', 'impact', ',', 'so', 'it', 'is', 'true', '.'] 1 0\n",
            "206 0 ['great', '.', 'it', 'sounds', 'good', 'to', 'me', '.'] 1 0\n",
            "207 0 ['so', ',', 'like', ',', 'for', 'example', ',', 'having', 'like', 'a', '-', 'a', 'set', 'out', 'meal', 'plan', ',', 'um', ',', 'you', 'know', ',', 'where', 'i', \"'\", 'm', 'eating', 'certain', 'food', 'groups', 'or', 'certain', 'macro', '##nut', '##rien', '##ts', ',', 'for', 'example', ',', 'that', 'wouldn', \"'\", 't', 'necessarily', 'follow', 'that', 'same', 'approach', '.'] 1 0\n",
            "208 2 ['i', 'don', \"'\", 't', 'even', 'really', 'know', '-'] 1 2\n",
            "209 2 ['um', ',', 'i', 'don', \"'\", 't', 'know', '.', 'i', \"'\", 'd', 'probably', 'have', 'to', 'sit', 'down', 'maybe', 'with', 'my', 'husband', 'and', 'try', 'to', 'figure', 'out', 'a', 'good', 'time', 'for', 'me', 'to', 'be', 'able', 'to', 'do', 'that', ',', 'where', 'he', \"'\", 'd', 'be', 'home', 'with', 'the', 'kids', 'and', 'i', \"'\", 'd', 'be', 'going', 'to', 'do', 'that', ',', 'whether', 'it', \"'\", 's', 'morning', '-', 'time', ',', 'evening', ',', 'maybe', 'the', 'weekends', '.'] 2 0\n",
            "211 2 ['-', 'regime', '##n', 'was', 'so', 'you', 'get', 'feedback', 'too', '.', 'and', 'then', '[', 'un', '##int', '##elli', '##gible', '00', ':', '05', ':', '37', ']', 'did', 'this', 'from', 'this', 'day', 'and', 'so', 'on', '.'] 2 1\n",
            "212 1 ['yeah', '.', 'maybe', '.'] 2 0\n",
            "214 1 ['no', ',', 'i', 'feel', 'really', 'good', '.', 'i', 'think', 'even', 'coming', 'in', ',', 'i', 'didn', \"'\", 't', 'have', 'a', 'like', 'step', '-', 'by', '-', 'step', 'idea', 'of', 'what', 'i', 'wanted', 'to', 'do', 'next', ',', 'but', 'no', ',', 'this', 'has', 'been', 'helpful', 'to', 'know', 'what', 'those', 'small', 'steps', 'are', ',', 'and', 'like', 'you', 'said', ',', 'hopefully', ',', 'i', 'do', 'start', 'feeling', 'better', '.', 'yeah', '.'] 1 0\n",
            "215 0 ['well', ',', 'like', 'i', 'said', ',', 'i', 'just', ',', 'i', \"'\", 've', 'identified', 'like', 'a', 'lot', 'of', 'things', 'that', 'i', 'think', 'would', 'be', 'good', '.', 'um', ',', 'if', 'i', 'were', 'to', 'be', 'more', 'active', 'and', 'i', 'definitely', 'wanna', 'have', 'that', 'improved', 'mood', 'and', 'energy', ',', 'um', ',', 'and', 'feel', 'better', 'about', 'myself', '.', 'um', ',', 'so', 'yeah', ',', 'all', 'of', 'those', 'things', 'i', 'think', 'are', 'what', \"'\", 's', 'really', 'driving', 'that', '-', 'that', 'rating', '.'] 1 0\n",
            "216 0 ['no', '.'] 2 1\n",
            "217 2 ['i', \"'\", 've', 'gotta', 'make', 'time', '.'] 2 0\n",
            "218 0 ['yeah', '.'] 2 0\n",
            "219 2 ['so', ',', 'um', ',', \"'\", 'cause', 'i', 'am', 'alone', '.'] 2 0\n",
            "221 0 ['right', 'now', ',', 'i', \"'\", 'm', 'probably', '-'] 0 2\n",
            "223 2 ['okay', ',', 'thank', 'you', 'doctor', ',', 'but', 'i', \"'\", 'm', 'just', 'concerned', 'about', 'how', 'i', 'can', 'possibly', 'lose', 'weight', 'now', 'since', 'work', 'is', 'so', 'busy', 'and', 'the', 'kids', 'take', 'up', 'so', 'much', 'of', 'my', 'time', '.'] 2 1\n",
            "224 1 ['exactly', ',', 'yeah', '.'] 1 0\n",
            "225 0 ['so', '-', 'and', 'i', 'don', \"'\", 't', 'wanna', 'impose', 'on', 'my', 'neighbors', 'or', 'my', 'friends', '.'] 2 0\n",
            "226 1 ['yeah', '.'] 0 2\n",
            "228 0 ['it', '-', 'it', 'is', '.', 'and', 'i', '-', '-', 'it', '-', 'it', 'may', 'be', 'why', 'i', 'can', '’', 't', 'really', 'run', 'again', ',', 'but', 'i', 'can', 'certainly', ',', 'you', 'know', ',', 'ride', 'a', 'stationary', 'bike', '-'] 1 2\n",
            "230 2 ['all', 'right', '.'] 2 0\n",
            "232 1 ['and', 'you', 'really', 'recommend', 'this', '?'] 2 0\n",
            "234 2 ['great', '.', 'yeah', ',', 'now', 'that', 'sounds', 'good', '.'] 2 0\n",
            "236 2 ['um', ',', 'would', 'that', 'be', 'kind', 'of', 'against', 'that', 'philosophy', 'too', 'or', 'i', 'guess', ',', 'can', 'you', 'explain', 'that', 'a', 'bit', 'more', '?'] 1 2\n",
            "239 2 ['no', ',', 'and', 'i', 'don', \"'\", 't', 'know', 'what', 'i', \"'\", 'm', 'doing', 'wrong', 'because', 'i', 'keep', 'trying', 'the', 'exercise', 'but', 'nothing', \"'\", 's', 'happening', '.'] 2 0\n",
            "240 0 ['i', \"'\", 've', 'gotta', 'make', 'time', '.'] 1 0\n",
            "241 0 ['i', 'don', \"'\", 't', 'know', '.', 'i', 'guess', 'there', \"'\", 's', 'kind', 'of', 'an', 'adrenaline', 'rush', 'to', 'it', '.', 'kinda', 'almost', 'like', ',', 'you', 'know', ',', 'uh', ',', 'kind', 'of', 'a', 'high', ',', 'i', 'guess', '.'] 2 0\n",
            "242 2 ['well', ',', 'i', \"'\", 'm', 'here', 'now', ',', 'so', 'yeah', ',', 'okay', ',', 'if', 'it', \"'\", 's', 'a', 'couple', 'of', 'minutes', ',', 'yeah', '?'] 1 0\n",
            "243 2 ['well', ',', 'if', 'i', 'could', 'just', 'get', 'myself', 'over', 'there', 'once', ',', \"'\", 'cause', 'usually', 'that', '’', 's', 'the', 'hardest', 'thing', '.', 'it', '’', 's', 'just', 'going', 'there', '.', 'so', 'i', 'think', 'that', \"'\", 's', '-', '-', 'you', 'know', ',', 'i', '’', 've', 'thought', 'about', 'it', 'a', 'little', 'bit', ',', 'i', 'think', 'i', 'just', 'need', 'to', 'make', 'that', 'first', 'trip', 'over', 'there', 'and', 'just', 'kind', 'of', 'to', 'take', 'it', 'easy', 'that', 'first', 'time', '.', 'just', 'show', 'up', \"'\", 'cause', 'i', 'think', 'that', '’', 's', 'really', 'what', 'i', 'need', 'to', 'do', '.', 'i', 'just', '##t', 'need', 'to', 'go', 'over', 'there', '.'] 2 0\n",
            "245 0 ['well', ',', 'and', 'i', '-', '-', 'but', 'i', 'was', 'working', 'at', 'a', 'different', 'company', ',', 'where', 'i', 'had', 'a', 'little', 'bit', 'different', 'schedule', ',', 'a', 'little', 'more', 'free', 'time', 'than', 'i', 'have', 'now', ',', 'so', 'i', 'just', 'don', \"'\", 't', 'have', 'the', 'time', 'like', 'i', 'used', 'to', '.'] 1 2\n",
            "247 0 ['really', '?'] 1 0\n",
            "249 2 ['that', 'i', \"'\", 'll', '-', 'that', 'i', \"'\", 'll', 'fall', 'again', '.'] 2 0\n",
            "251 2 ['it', \"'\", 's', 'crazy', ',', 'it', \"'\", 's', 'crazy', '.'] 1 2\n",
            "254 0 ['yeah', ',', 'i', 'mean', ',', 'there', 'are', 'rather', 'other', 'things', ',', 'but', 'i', 'mean', ',', 'yeah', ',', 'the', 'weight', 'is', 'a', '-', 'is', 'a', '-', 'is', 'a', '-', 'something', 'i', 'would', 'like', 'to', 'get', 'hold', 'off', '.', 'you', 'get', 'on', '[', 'ina', '##udi', '##ble', '00', ':', '03', ':', '17', ']'] 0 2\n",
            "262 2 ['so', 'it', \"'\", 's', 'kinda', 'hard', 'to', 'meet', 'up', 'with', 'somebody', 'that', 'can', 'kind', 'of', 'maybe', 'kind', 'of', 'give', 'you', 'a', 'push', '[', 'un', '##int', '##elli', '##gible', '00', ':', '06', ':', '38', ']', '-'] 2 1\n",
            "263 2 ['so', 'i', '—'] 1 0\n",
            "265 2 ['mm', '-', 'hmm', '.'] 2 0\n",
            "266 0 ['like', 'ever', 'since', 'i', 'started', 'being', 'a', 'teen', ',', 'like', 'this', 'has', 'always', 'been', 'a', 'goal', 'of', 'mine', ',', 'like', ',', 'especially', \"'\", 'cause', 'all', 'my', 'friends', 'play', 'soccer', ',', 'and', 'like', '-'] 1 0\n",
            "269 2 ['well', ',', 'i', '-', 'i', 'hadn', \"'\", 't', 'really', 'thought', 'about', 'it', ',', 'but', 'yeah', 'i', 'guess', ',', 'i', 'guess', '.'] 2 0\n",
            "270 0 ['okay', '.'] 2 0\n",
            "271 2 ['so', 'i', 'am', ',', 'um', ',', '28', '.', 'and', 'i', 'moved', 'out', 'to', 'arizona', 'about', 'six', 'months', 'ago', '.', 'um', ',', 'i', 'really', 'enjoy', 'spending', 'time', 'with', 'my', 'family', 'and', 'hanging', 'out', 'with', 'friends', 'whenever', 'i', 'can', '.', 'work', 'keeps', 'me', 'pretty', 'busy', '.', 'um', ',', 'but', 'i', \"'\", 'm', 'really', ',', 'um', ',', 'looking', 'to', 'kind', 'of', 'make', 'some', 'changes', 'to', 'my', 'diet', 'and', 'physical', 'activity', '.', 'i', \"'\", 'm', 'not', 'really', 'happy', 'with', 'where', 'my', 'weight', \"'\", 's', 'at', 'right', 'now', ',', 'and', ',', 'uh', ',', 'so', 'i', 'thought', 'it', \"'\", 'd', 'be', 'good', 'to', 'come', 'and', 'talk', 'with', 'you', 'about', 'some', 'of', 'that', 'stuff', '.'] 2 0\n",
            "274 0 ['thanks', 'for', 'having', 'me', '.'] 2 0\n",
            "275 1 ['um', ',', 'so', 'i', 'don', \"'\", 't', 'really', 'need', 'a', 'discussion', ',', 'it', \"'\", 's', '-', 'it', \"'\", 's', 'just', 'i', \"'\", 've', 'got', 'too', 'much', 'to', 'do', 'at', 'the', 'moment', ',', 'you', 'know', '?'] 1 0\n",
            "278 0 ['-', 'really', 'a', 'little', 'frightened', 'that', 'what', 'if', '-', 'what', 'if', 'i', 'fall', 'down', 'and', '-', 'and', '-', 'and', 'nobody', 'comes', 'around', 'and', 'i', \"'\", 'm', 'lying', 'there', 'for', 'two', 'days', ',', 'you', 'know', '.', 'i', 'may', 'have', 'heard', 'about', 'that', '.'] 1 0\n",
            "279 0 ['really', '?'] 2 0\n",
            "280 2 ['yeah', '.', 'i', 'was', 'going', 'literally', 'every', 'other', 'day', ',', 'you', 'know', '.', 'and', 'then', ',', 'some', 'days', 'i', 'would', ',', 'you', 'know', ',', 'i', '’', 'd', 'run', ',', 'and', 'i', '’', 'd', 'go', 'to', 'the', 'gym', 'the', 'next', 'day', ',', 'so', 'i', 'would', '-', '-', 'i', 'was', 'very', '-', '-', 'i', 'don', '’', 't', 'really', 'feel', 'it', 'necessary', 'to', 'get', 'back', 'to', 'that', 'level', ',', 'but', 'i', 'need', 'to', 'do', 'something', 'cause', 'i', '’', 'm', 'doing', 'nothing', 'right', 'now', '.'] 1 0\n",
            "281 0 ['-', 'that', 'i', 'could', 'do', 'for', 'longer', 'periods', 'versus', 'more', 'of', 'like', 'you', 'said', ',', 'the', 'pre', '##script', '##ive', 'approach', '.'] 1 0\n",
            "282 2 ['no', ',', 'by', 'all', 'means', '.', 'i', 'know', 'we', 'have', 'to', 'discuss', 'it', '.'] 2 0\n",
            "283 0 ['um', ',', 'i', 'definitely', ',', 'uh', ',', 'you', 'know', ',', 'i', '-', 'i', 'strive', 'to', 'be', 'physically', 'healthy', ',', 'but', 'i', 'also', 'have', 'in', 'my', 'life', 'seeing', 'how', 'that', 'impacts', 'me', 'mentally', '.', 'um', ',', 'so', 'i', 'think', 'if', 'i', \"'\", 'm', '-', 'if', 'i', \"'\", 'm', 'able', 'to', 'do', 'the', 'things', 'that', 'i', 'wanna', 'do', 'and', ',', 'um', ',', 'you', 'know', ',', 'that', 'i', \"'\", 'm', 'feeling', 'good', 'about', 'where', 'i', \"'\", 'm', 'at', 'mentally', ',', 'then', 'that', \"'\", 's', 'kind', 'of', 'my', 'end', 'goal', ',', 'always', '.', 'um', ',', 'yeah', ',', 'so', 'this', 'body', 'dissatisfaction', 'piece', 'has', 'really', 'just', 'kinda', 'thrown', 'a', 'wren', '##ch', 'in', 'that', 'and', 'it', \"'\", 's', 'been', 'enough', 'of', 'a', 'challenge', 'that', 'i', 'thought', 'i', 'should', 'seek', 'out', 'someone', 'who'] 2 0\n",
            "287 0 ['pretty', 'good', '.'] 2 0\n",
            "288 1 ['just', ',', 'i', 'don', \"'\", 't', 'feel', 'comfortable', '.'] 1 0\n",
            "289 0 ['so', ',', 'am', 'i', 'being', 'a', 'baby', '?'] 1 2\n",
            "291 2 ['mm', '-', 'hmm', '.'] 2 0\n",
            "294 2 ['-', 'time', 'there', ',', 'time', 'back', '.', 'i', 'mean', ',', 'it', \"'\", 's', 'not', 'just', 'an', 'hour', ',', 'it', \"'\", 's', 'like', 'two', 'hours', ',', 'realistic', '##ally', '.'] 1 2\n",
            "296 1 ['so', 'i', \"'\", 'm', '-', 'i', \"'\", 'm', '-', 'i', 'cut', 'back', ',', 'and', 'i', '-', 'i', 'don', \"'\", 't', 'know', 'if', 'i', 'should', 'really', 'even', 'continue', 'the', 'tai', 'chi', 'because', 'it', \"'\", 's', '-', 'it', \"'\", 's', 'very', 'demanding', '.'] 1 2\n",
            "297 2 ['okay', ',', 'yeah', '.'] 2 0\n",
            "298 2 ['yeah', ',', 'that', \"'\", 's', 'right', ',', 'well', 'i', '-'] 2 0\n",
            "299 2 ['-', 'would', 'happen', 'and', 'i', 'wouldn', \"'\", 't', 'have', 'any', '-'] 1 2\n",
            "300 0 ['right', '?'] 2 1\n",
            "301 0 ['um', ',', 'a', 'little', 'bit', 'less', 'junk', 'food', '.', 'um', ',', 'like', 'at', 'times', ',', 'when', 'i', \"'\", 'm', 'like', 'i', 'feel', 'like', ',', '\"', 'oh', ',', 'i', 'think', 'i', \"'\", 'll', 'just', 'go', 'have', 'a', 'candy', 'bar', ',', '\"', 'or', 'some', 'worthless', 'thing', 'like', 'that', 'i', \"'\", 'll', 'actually', 'have', 'second', 'thoughts', 'before', 'i', 'do', 'it', '.'] 2 0\n",
            "302 2 ['right', ',', 'yeah', '.'] 1 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else:\n",
        "            return super().find_class(module, name)"
      ],
      "metadata": {
        "id": "EoTxvkzvjc7K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(root_folder+'random'+str(0)+'_seed'+str(0)+'_laend_fisher_task'+str(3)+'.pkl', 'rb') as handle:\n",
        "    alpha_laend = CPU_Unpickler(handle).load()\n",
        "with open(root_folder+'random'+str(0)+'_seed'+str(0)+'_lastart_fisher_task'+str(3)+'.pkl', 'rb') as handle:\n",
        "    alpha_lastart = CPU_Unpickler(handle).load()"
      ],
      "metadata": {
        "id": "bsc5ndUBZoSu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(root_folder+'random'+str(0)+'_seed'+str(0)+'_laend_graddir_task'+str(3)+'.pkl', 'rb') as handle:\n",
        "    graddir_laend = CPU_Unpickler(handle).load()\n",
        "with open(root_folder+'random'+str(0)+'_seed'+str(0)+'_lastart_graddir_task'+str(3)+'.pkl', 'rb') as handle:\n",
        "    graddir_lastart = CPU_Unpickler(handle).load()"
      ],
      "metadata": {
        "id": "7VlCRw9Hb2_N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_delta = []\n",
        "for k,v in alpha_lastart.items():\n",
        "    # if ('adapter' not in k) and ('layernorm' not in k):\n",
        "    #     print(k,torch.sum(v),torch.sum(alpha_lastart[k]))\n",
        "    #     break\n",
        "    # if ('adapter' in k) or ('layernorm' in k):\n",
        "    if k == 'bert.encoder.layer.11.attention.output.adapter.fc1.weight':\n",
        "        print(k)\n",
        "        alpha_delta = (alpha_laend[k] - v).flatten()\n",
        "        graddir = (graddir_laend[k] - graddir_lastart[k])/304 # Change this later\n",
        "        graddir = torch.abs(graddir).flatten()\n",
        "        # print(alpha_delta.shape,graddir.shape)\n",
        "        # print(torch.min(alpha_delta))\n",
        "        # print(torch.quantile(alpha_delta,0.25))\n",
        "        # print(torch.quantile(alpha_delta,0.50))\n",
        "        # print(torch.quantile(alpha_delta,0.75))\n",
        "        # print(torch.max(alpha_delta))\n",
        "        # print(\"\")\n",
        "        # print(torch.min(graddir))\n",
        "        # print(torch.quantile(graddir,0.25))\n",
        "        # print(torch.quantile(graddir,0.50))\n",
        "        # print(torch.quantile(graddir,0.75))\n",
        "        # print(torch.max(graddir))\n",
        "        # print(\"\")\n",
        "        print(torch.max((graddir-alpha_delta)/graddir))\n",
        "        check_ind = torch.where(((graddir-alpha_delta)/graddir)>1)\n",
        "        # print(check_ind[0])\n",
        "        print(check_ind[0].shape)\n",
        "        print(torch.index_select(graddir, 0, check_ind[0]))\n",
        "        print(torch.index_select(alpha_delta, 0, check_ind[0]))\n",
        "        # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz-muPaNatSc",
        "outputId": "d68495fd-42f9-47d6-8aa0-a14ba98d2038"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.11.attention.output.adapter.fc1.weight\n",
            "tensor(126.9122)\n",
            "torch.Size([149])\n",
            "tensor([1.1157e-03, 2.1123e-03, 5.1075e-04, 1.0598e-04, 6.3452e-04, 8.4735e-04,\n",
            "        9.0754e-04, 2.7210e-04, 1.6401e-03, 1.2305e-03, 2.2131e-03, 1.3060e-03,\n",
            "        6.6497e-04, 1.5176e-03, 1.7366e-03, 2.5652e-03, 2.1490e-03, 1.8265e-03,\n",
            "        7.8753e-04, 4.5629e-04, 7.9865e-04, 9.3290e-04, 1.7996e-04, 1.5798e-03,\n",
            "        1.3138e-04, 1.4432e-03, 1.3869e-03, 2.0308e-03, 9.8182e-04, 3.3567e-03,\n",
            "        1.6359e-03, 2.4473e-03, 1.0995e-03, 1.6878e-03, 8.4740e-04, 7.7171e-04,\n",
            "        4.2981e-05, 1.0762e-03, 6.3649e-04, 7.0316e-04, 2.2089e-03, 5.1957e-04,\n",
            "        5.7276e-04, 3.2849e-04, 2.6942e-04, 2.8449e-04, 1.4018e-03, 3.3533e-04,\n",
            "        2.8259e-03, 8.7006e-04, 2.7313e-03, 3.2747e-03, 1.3399e-03, 4.0428e-04,\n",
            "        3.5311e-04, 3.5652e-04, 9.8748e-04, 1.6047e-04, 8.7393e-05, 1.3044e-03,\n",
            "        1.5716e-04, 1.2781e-04, 1.1850e-04, 1.4359e-04, 1.1736e-04, 5.5749e-05,\n",
            "        3.6906e-05, 6.9603e-05, 6.4094e-05, 3.4689e-05, 1.6075e-04, 9.6293e-06,\n",
            "        1.2450e-03, 8.7235e-04, 5.5065e-04, 8.3229e-04, 1.3521e-03, 2.6565e-04,\n",
            "        2.6258e-03, 3.9337e-03, 1.1653e-03, 5.1477e-04, 1.0911e-04, 2.1554e-03,\n",
            "        9.0109e-04, 7.9599e-04, 8.7268e-05, 1.5422e-03, 6.1410e-04, 2.9553e-04,\n",
            "        7.7456e-04, 7.0255e-04, 1.9298e-04, 1.2063e-03, 3.6363e-04, 2.0571e-03,\n",
            "        1.5078e-03, 1.1491e-03, 1.4240e-04, 2.7268e-04, 2.0228e-04, 8.7246e-05,\n",
            "        3.2650e-05, 4.5107e-05, 3.8975e-05, 8.5140e-07, 2.2522e-04, 2.6597e-04,\n",
            "        2.8333e-04, 4.0579e-04, 3.3200e-04, 2.3521e-04, 3.4157e-05, 3.9281e-04,\n",
            "        2.8525e-03, 1.2870e-03, 1.1836e-03, 1.7524e-04, 1.1881e-04, 1.2758e-04,\n",
            "        6.6936e-05, 7.1971e-05, 2.1557e-04, 5.5965e-03, 2.3757e-03, 7.7493e-04,\n",
            "        9.8739e-04, 1.5202e-06, 7.6898e-04, 5.2012e-03, 2.2775e-04, 6.6935e-04,\n",
            "        2.1959e-03, 7.2728e-04, 1.6875e-03, 1.8490e-03, 2.3517e-03, 1.2742e-03,\n",
            "        6.7378e-04, 1.1015e-03, 1.0627e-04, 2.2416e-04, 5.8622e-05, 2.2912e-04,\n",
            "        3.2161e-04, 9.6308e-04, 6.1304e-04, 2.6519e-03, 7.8317e-03])\n",
            "tensor([-7.3713e-05, -2.4354e-04, -9.0174e-05, -6.9671e-05, -1.0854e-04,\n",
            "        -4.2341e-04, -4.2938e-04, -1.3553e-05, -6.2316e-05, -8.7257e-04,\n",
            "        -9.4170e-04, -4.6544e-04, -8.0846e-04, -3.1511e-04, -9.4308e-04,\n",
            "        -1.1160e-03, -9.3339e-05, -1.3747e-03, -6.3418e-04, -2.3816e-04,\n",
            "        -7.4588e-05, -4.2951e-04, -2.4840e-04, -3.1001e-04, -1.1313e-04,\n",
            "        -1.5813e-04, -3.5408e-04, -3.6255e-05, -5.6950e-04, -2.9446e-04,\n",
            "        -2.2020e-04, -2.0516e-04, -2.7450e-04, -7.5092e-05, -1.8004e-04,\n",
            "        -3.6473e-05, -2.2591e-04, -3.2309e-05, -1.8335e-04, -3.0844e-04,\n",
            "        -5.2214e-05, -5.0180e-04, -2.6128e-04, -2.1834e-04, -6.1227e-04,\n",
            "        -6.1590e-04, -6.5275e-04, -3.7359e-04, -1.7491e-06, -1.8067e-04,\n",
            "        -4.2011e-04, -2.5723e-05, -4.4933e-04, -3.0689e-04, -1.9294e-04,\n",
            "        -1.4495e-04, -1.1375e-04, -1.1579e-05, -1.4578e-04, -4.8350e-04,\n",
            "        -1.5124e-05, -1.1578e-05, -6.3549e-06, -2.1938e-05, -4.9448e-06,\n",
            "        -2.6736e-05, -4.4879e-05, -2.8570e-05, -6.6800e-06, -2.9049e-07,\n",
            "        -4.5617e-06, -4.3767e-05, -2.5014e-05, -6.5093e-04, -2.9403e-04,\n",
            "        -2.3417e-04, -1.7790e-05, -1.7749e-04, -4.1947e-04, -1.6634e-05,\n",
            "        -2.8109e-05, -1.4576e-04, -8.8954e-04, -2.0027e-04, -7.9337e-04,\n",
            "        -1.7161e-04, -4.1667e-04, -2.5720e-04, -7.6998e-05, -9.2097e-04,\n",
            "        -2.6522e-04, -6.8027e-04, -8.0632e-04, -2.0441e-04, -2.2372e-04,\n",
            "        -3.5930e-04, -1.1053e-03, -6.3012e-04, -7.3806e-05, -4.1882e-06,\n",
            "        -1.4377e-05, -5.6478e-05, -4.2068e-05, -1.0987e-05, -2.4220e-06,\n",
            "        -7.1864e-06, -1.2216e-05, -1.0512e-05, -3.5955e-05, -1.2907e-04,\n",
            "        -3.4830e-05, -4.9583e-05, -3.1496e-04, -3.7695e-05, -5.4351e-05,\n",
            "        -1.4786e-04, -7.6453e-05, -3.5497e-05, -1.3089e-04, -8.5397e-05,\n",
            "        -4.2755e-05, -8.5485e-05, -2.2237e-05, -1.5578e-04, -5.2695e-04,\n",
            "        -1.0322e-04, -6.2967e-04, -1.9141e-04, -2.0935e-04, -1.3147e-04,\n",
            "        -1.9998e-05, -1.9568e-04, -2.5397e-04, -2.8044e-04, -1.2527e-05,\n",
            "        -6.2335e-04, -2.5731e-04, -3.7675e-05, -6.7708e-04, -5.3554e-04,\n",
            "        -3.3776e-05, -9.8750e-05, -2.8178e-04, -4.4154e-06, -2.1826e-04,\n",
            "        -9.5530e-04, -6.8512e-05, -2.4368e-04, -2.2779e-04])\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DccffCSEm9u",
        "outputId": "54daca81-395b-453e-b37b-941cc576c7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_rxa-gh8E8hg"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200r-EWCFreeze-v2.5.zip"
      ],
      "metadata": {
        "id": "iFXFOz4rO-4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372f90a8-8add-4ed4-fa71-22b9fc23aab1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200r-EWCFreeze-v2.5.zip, /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200r-EWCFreeze-v2.5.zip.zip or /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200r-EWCFreeze-v2.5.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuRBS2.2-EWCMaxL1/hwu64_bert_adapter_ewc_random'\n",
        "# path = 's200r-EWCFreeze-v2.5/bert_dis_bert_adapter_ewc_freeze_random'"
      ],
      "metadata": {
        "id": "AyHDP977FE-L"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathb = '/content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-AdapterSEQ/hwu64_bert_adapter_seq_random'"
      ],
      "metadata": {
        "id": "sgNlDbu1zP9W"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best F1 Analysis"
      ],
      "metadata": {
        "id": "Nx2oHlhzlVOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "# EWC/CTR/SEQ: check best f1 location\n",
        "best_f1_location_check = []\n",
        "overfit_task = []\n",
        "kt_task = []\n",
        "for seed_idx in [101,2650,0]:\n",
        "    for rand_idx in range(7):\n",
        "        list_of_lists = []\n",
        "        with open(path+str(rand_idx)+'_seed'+str(seed_idx)+'_f1.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                inner_list = [float(elt.strip()) for elt in line.split('\\t')]\n",
        "                list_of_lists.append(inner_list)\n",
        "        f1_matrix = np.array(list_of_lists)\n",
        "        assert f1_matrix.shape == (6,6)\n",
        "        temp_best = []\n",
        "        for i in range(5): # Exclude the last task\n",
        "            location = np.argmax(f1_matrix[i:,i])\n",
        "            best_f1_location_check.append(location==0)\n",
        "            if location==0:\n",
        "                overfit_task.append(i)\n",
        "            if location!=0:\n",
        "                kt_task.append(i)\n",
        "print(np.mean(best_f1_location_check))\n",
        "print('kt tasks:',Counter(kt_task))\n",
        "print('overfit tasks:',Counter(overfit_task))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGo6BamNBcKA",
        "outputId": "9acde819-011f-4c4b-fbc0-3ae04d831c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8761904761904762\n",
            "kt tasks: Counter({3: 5, 2: 4, 0: 4})\n",
            "overfit tasks: Counter({1: 21, 4: 21, 0: 17, 2: 17, 3: 16})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "2WNXtwV-lS6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1 = []\n",
        "forgetting = []\n",
        "best_f1 = []\n",
        "worst_f1 = []\n",
        "for seed_idx in [0]:\n",
        "# for seed_idx in [101,2650,0]:\n",
        "    # for rand_idx in range(7):\n",
        "    # for rand_idx in [0,2,10,12,13,14,15]:\n",
        "    for rand_idx in [0,3,6]:\n",
        "    # for rand_idx in [0,10,13]:\n",
        "    # for rand_idx in [0]:\n",
        "        list_of_lists = []\n",
        "        with open(path+str(rand_idx)+'_seed'+str(seed_idx)+'_f1.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                inner_list = [float(elt.strip()) for elt in line.split('\\t')]\n",
        "                list_of_lists.append(inner_list)\n",
        "        f1_matrix = np.array(list_of_lists)\n",
        "        assert f1_matrix.shape == (6,6)\n",
        "        # print(f1_matrix)\n",
        "        # if 'annomi' in path and 'rrr' in path and rand_idx==0:\n",
        "            # print('modified for annomi')\n",
        "            # overall_f1.append(np.mean(f1_matrix[3,:]))\n",
        "            # temp_forgetting = []\n",
        "            # for i in range(3):\n",
        "            #     temp_forgetting.append(np.max(f1_matrix[i:-3,i])-f1_matrix[3,i])\n",
        "            # forgetting.append(np.mean(temp_forgetting))\n",
        "            # temp_best = []\n",
        "            # for i in range(4):\n",
        "            #     temp_best.append(np.max(f1_matrix[i:,i]))\n",
        "            # best_f1.append(np.mean(temp_best))\n",
        "            # temp_worst = []\n",
        "            # for i in range(4):\n",
        "            #     temp_worst.append(np.min(f1_matrix[i:-2,i]))\n",
        "            # worst_f1.append(np.mean(temp_worst))\n",
        "        # else:\n",
        "        overall_f1.append(np.mean(f1_matrix[5,:]))\n",
        "        temp_forgetting = []\n",
        "        for i in range(5):\n",
        "            temp_forgetting.append(np.max(f1_matrix[i:-1,i])-f1_matrix[5,i])\n",
        "        forgetting.append(np.mean(temp_forgetting))\n",
        "        temp_best = []\n",
        "        for i in range(6):\n",
        "            temp_best.append(np.max(f1_matrix[i:,i]))\n",
        "        best_f1.append(np.mean(temp_best))\n",
        "        temp_worst = []\n",
        "        for i in range(6):\n",
        "            temp_worst.append(np.min(f1_matrix[i:,i]))\n",
        "        worst_f1.append(np.mean(temp_worst))\n",
        "# assert len(overall_f1)==21\n",
        "# assert len(forgetting)==21\n",
        "# assert len(best_f1)==21\n",
        "# assert len(worst_f1)==21\n",
        "print(len(overall_f1))"
      ],
      "metadata": {
        "id": "xSNnsRQ-FioB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e47114-5bca-4f9b-e019-01e12c70e4d5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1 = [val*100 for val in overall_f1]\n",
        "print(np.mean(overall_f1), np.std(overall_f1))\n",
        "print(np.mean(forgetting)*100)\n",
        "print(np.mean(best_f1)*100)\n",
        "print(np.mean(worst_f1)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxrsTCw1G6w-",
        "outputId": "a20a8bf8-902a-44e8-852f-a73446b31738"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.97 3.0496010668063915\n",
            "16.444\n",
            "46.673333333333325\n",
            "31.64944444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200r-EWCFreeze-v2.1.zip"
      ],
      "metadata": {
        "id": "C10mEOruMmzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path2 = '/content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStr-TaskDrop/annomi_taskdrop_random'\n",
        "path2 = 's200r-EWCFreeze-v2.1/bert_dis_bert_adapter_ewc_freeze_random'"
      ],
      "metadata": {
        "id": "wKz_KXurNdI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1_compare = []\n",
        "forgetting_compare = []\n",
        "best_f1_compare = []\n",
        "worst_f1_compare = []\n",
        "for seed_idx in [0]:\n",
        "# for seed_idx in [101,2650,0]:\n",
        "    # for rand_idx in range(7):\n",
        "    # for rand_idx in [0,2,10,12,13,14,15]:\n",
        "    for rand_idx in [0,3,6]:\n",
        "        list_of_lists = []\n",
        "        with open(path2+str(rand_idx)+'_seed'+str(seed_idx)+'_f1.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                inner_list = [float(elt.strip()) for elt in line.split('\\t')]\n",
        "                list_of_lists.append(inner_list)\n",
        "        f1_matrix = np.array(list_of_lists)\n",
        "        assert f1_matrix.shape == (6,6)\n",
        "        # print(f1_matrix)\n",
        "        # if 'annomi' in path2 and 'replay' in path2 and rand_idx==0:\n",
        "        #     print('modified for annomi')\n",
        "        #     overall_f1_compare.append(np.mean(f1_matrix[3,:]))\n",
        "        #     temp_forgetting = []\n",
        "        #     for i in range(3):\n",
        "        #         temp_forgetting.append(np.max(f1_matrix[i:-3,i])-f1_matrix[3,i])\n",
        "        #     forgetting_compare.append(np.mean(temp_forgetting))\n",
        "        #     temp_best = []\n",
        "        #     for i in range(4):\n",
        "        #         temp_best.append(np.max(f1_matrix[i:,i]))\n",
        "        #     best_f1_compare.append(np.mean(temp_best))\n",
        "        #     temp_worst = []\n",
        "        #     for i in range(4):\n",
        "        #         temp_worst.append(np.min(f1_matrix[i:-2,i]))\n",
        "        #     worst_f1_compare.append(np.mean(temp_worst))\n",
        "        # else:\n",
        "        overall_f1_compare.append(np.mean(f1_matrix[5,:]))\n",
        "        temp_forgetting = []\n",
        "        for i in range(5):\n",
        "            temp_forgetting.append(np.max(f1_matrix[i:-1,i])-f1_matrix[5,i])\n",
        "        forgetting_compare.append(np.mean(temp_forgetting))\n",
        "        temp_best = []\n",
        "        for i in range(6):\n",
        "            temp_best.append(np.max(f1_matrix[i:,i]))\n",
        "        best_f1_compare.append(np.mean(temp_best))\n",
        "        temp_worst = []\n",
        "        for i in range(6):\n",
        "            temp_worst.append(np.min(f1_matrix[i:,i]))\n",
        "        worst_f1_compare.append(np.mean(temp_worst))\n",
        "# assert len(overall_f1_compare)==21\n",
        "# assert len(forgetting_compare)==21\n",
        "# assert len(best_f1_compare)==21\n",
        "# assert len(worst_f1_compare)==21\n",
        "print(len(overall_f1_compare))"
      ],
      "metadata": {
        "id": "h3imUlpSNoq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2a32cf-f0bc-4add-dd2c-fb65d163235c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1_compare = [val*100 for val in overall_f1_compare]\n",
        "print(np.mean(overall_f1_compare), np.std(overall_f1_compare))\n",
        "print(np.mean(forgetting_compare)*100)\n",
        "print(np.mean(best_f1_compare)*100)\n",
        "print(np.mean(worst_f1_compare)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKOB_IErdB_I",
        "outputId": "7d423288-576d-401d-a6d6-c01afed243fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83.22333333333334 1.8766049920791208\n",
            "1.328000000000001\n",
            "84.71222222222222\n",
            "69.97888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diaz+Chaudhary Metrics"
      ],
      "metadata": {
        "id": "PQ7D0HGjeLFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mtl = [0.8558,0.8918,0.8365,0.9120,0.8918,0.8038,0.9120]"
      ],
      "metadata": {
        "id": "PIsBF9j8kAQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1 = []\n",
        "bwt1 = []\n",
        "bwt2 = []\n",
        "bwt3 = []\n",
        "fwt = []\n",
        "# rem = []\n",
        "# pbwt = []\n",
        "# intra = []\n",
        "for seed_idx in [0]:\n",
        "# for seed_idx in [101,2650,0]:\n",
        "    mtl_idx=0\n",
        "    # for rand_idx in range(7):\n",
        "    for rand_idx in [0,3,6]:\n",
        "    # for rand_idx in [0,2,10,12,13,14,15]:\n",
        "        list_of_lists = []\n",
        "        with open(path+str(rand_idx)+'_seed'+str(seed_idx)+'_f1.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                inner_list = [float(elt.strip()) for elt in line.split('\\t')]\n",
        "                list_of_lists.append(inner_list)\n",
        "        f1_matrix = np.array(list_of_lists)\n",
        "        assert f1_matrix.shape == (6,6)\n",
        "        # print(f1_matrix)\n",
        "        temp_acc = []\n",
        "        for i in range(6):\n",
        "            temp_acc.append(np.mean(f1_matrix[i,:i+1]))\n",
        "        overall_f1.append(np.mean(temp_acc))\n",
        "        temp_bwt1 = []\n",
        "        for i in [1,2,3,4,5]:\n",
        "            for j in range(0,i):\n",
        "                temp_bwt1.append(f1_matrix[i,j]-f1_matrix[j,j])\n",
        "        bwt1.append(np.mean(temp_bwt1))\n",
        "        temp_bwt2 = []\n",
        "        for i in [1,2,3,4,5]:\n",
        "            for j in range(0,i):\n",
        "                temp_bwt2.append(f1_matrix[i,j]-np.max([f1_matrix[k,j] for k in range(j,i)]))\n",
        "                # print(i,j,[f1_matrix[k,j] for k in range(j,i)])\n",
        "        bwt2.append(np.mean(temp_bwt2))\n",
        "        temp_bwt3 = []\n",
        "        for i in [1,2,3,4,5]:\n",
        "            for j in range(0,i):\n",
        "                temp_bwt3.append(f1_matrix[i,j]-f1_matrix[i-1,j])\n",
        "        bwt3.append(np.mean(temp_bwt3))\n",
        "        # rem.append(1-\n",
        "        #            np.absolute(\n",
        "        #                np.minimum(np.mean(temp_bwt),0)\n",
        "        #                )\n",
        "        #            )\n",
        "        # pbwt.append(np.maximum(np.mean(temp_bwt),0))\n",
        "        # intra.append(mtl[mtl_idx]-f1_matrix[5,5])\n",
        "        # mtl_idx+=1\n",
        "        list_of_lists = []\n",
        "        with open(pathb+str(rand_idx)+'_seed'+str(seed_idx)+'_f1.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                inner_list = [float(elt.strip()) for elt in line.split('\\t')]\n",
        "                list_of_lists.append(inner_list)\n",
        "        f1_matrix_seq = np.array(list_of_lists)\n",
        "        temp_fwt = []\n",
        "        for i in [1,2,3,4,5]:\n",
        "            temp_fwt.append(f1_matrix[i,i]-f1_matrix_seq[i,i])\n",
        "        fwt.append(np.mean(temp_fwt))\n",
        "# assert len(overall_f1)==21\n",
        "# assert len(bwt)==21\n",
        "# assert len(rem)==21\n",
        "# assert len(pbwt)==21\n",
        "# assert len(intra)==21\n",
        "print(len(overall_f1))"
      ],
      "metadata": {
        "id": "uDlPIUVkeKL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f10c25-8c3c-427c-a54f-343e670bf14c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1 = [val*100 for val in overall_f1]\n",
        "print(np.mean(overall_f1), np.std(overall_f1))\n",
        "print(np.mean(bwt1)*100)\n",
        "print(np.mean(bwt2)*100)\n",
        "print(np.mean(bwt3)*100)\n",
        "print(np.mean(fwt)*100)\n",
        "# print(np.mean(rem)*100)\n",
        "# print(np.mean(pbwt)*100)\n",
        "# print(np.mean(intra)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FEnJnTJf21i",
        "outputId": "69f142a6-6a32-46d5-e503-1f5ffc209eb2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94.81502777777779 0.45978561328644224\n",
            "-2.1122222222222233\n",
            "-2.1122222222222233\n",
            "-0.5948888888888886\n",
            "8.62733333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Significance Test"
      ],
      "metadata": {
        "id": "sGclk8rhlZxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind, ttest_rel"
      ],
      "metadata": {
        "id": "S5w_ZXwkOY2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ttest_rel(overall_f1,overall_f1_compare, alternative='greater')\n",
        "t = res[0]\n",
        "p = res[1]\n",
        "alpha = 0.1\n",
        "# test if A > B\n",
        "if p < alpha and t > 0:\n",
        "  # reject the null hypothesis (no effect) => A > B !!\n",
        "  print('Yes!', p)\n",
        "else:\n",
        "  # accept the null hypothesis => no effect\n",
        "  print('No!', p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iQnO3IcU80i",
        "outputId": "335ac788-4235-455d-8bde-d5c87ed38108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes! 0.03357277954113428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = ttest_ind(forgetting_compare,forgetting)\n",
        "t = res[0]\n",
        "p = res[1]\n",
        "alpha = 0.1\n",
        "# test if A > B\n",
        "if p/2 < alpha and t>0:\n",
        "  # reject the null hypothesis (no effect) => A > B !!\n",
        "  print('Yes!')\n",
        "else:\n",
        "  # accept the null hypothesis => no effect\n",
        "  print('No!', p/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh7C-PMYOo_X",
        "outputId": "6426dadb-6dee-4f72-e329-22095ef212a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modified ParamCount - EWC Freeze"
      ],
      "metadata": {
        "id": "21YLXaaOlcep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch"
      ],
      "metadata": {
        "id": "VYQ0peqgmTwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else:\n",
        "            return super().find_class(module, name)"
      ],
      "metadata": {
        "id": "EhmYxyzWndeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = 's200r-EWCFreeze-v2.4/modified_paramcount_random'"
      ],
      "metadata": {
        "id": "_ICa2PIFl9nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_counts = {}\n",
        "for seed in [0,101,2650]:\n",
        "    for rand_idx in [0,3,6]:\n",
        "        for m in [1,2,3,4,5]:\n",
        "            with open(path3+str(rand_idx)+'_seed'+str(seed)+'model_'+str(m)+'.pkl', 'rb') as handle:\n",
        "                # temp = torch.load(handle, map_location=torch.device('cpu'))\n",
        "                temp = CPU_Unpickler(handle).load()\n",
        "                check_counts['random'+str(rand_idx)+'seed'+str(seed)+'model'+str(m)] = temp\n"
      ],
      "metadata": {
        "id": "2wndK2LslgW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in check_counts['random6seed2650model5'].items():\n",
        "  print(k,v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bogUMt12nudl",
        "outputId": "581d1a78-2ae1-43c9-a84f-c8cc08c526a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.0.attention.output.LayerNorm.weight tensor(767)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias tensor(763)\n",
            "bert.encoder.layer.0.attention.output.adapter.fc1.weight tensor(1526263)\n",
            "bert.encoder.layer.0.attention.output.adapter.fc1.bias tensor(1993)\n",
            "bert.encoder.layer.0.attention.output.adapter.fc2.weight tensor(1514594)\n",
            "bert.encoder.layer.0.attention.output.adapter.fc2.bias tensor(760)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight tensor(767)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias tensor(760)\n",
            "bert.encoder.layer.0.output.adapter.fc1.weight tensor(1529991)\n",
            "bert.encoder.layer.0.output.adapter.fc1.bias tensor(1993)\n",
            "bert.encoder.layer.0.output.adapter.fc2.weight tensor(1525499)\n",
            "bert.encoder.layer.0.output.adapter.fc2.bias tensor(761)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight tensor(767)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias tensor(763)\n",
            "bert.encoder.layer.1.attention.output.adapter.fc1.weight tensor(1528659)\n",
            "bert.encoder.layer.1.attention.output.adapter.fc1.bias tensor(1991)\n",
            "bert.encoder.layer.1.attention.output.adapter.fc2.weight tensor(1522899)\n",
            "bert.encoder.layer.1.attention.output.adapter.fc2.bias tensor(763)\n",
            "bert.encoder.layer.1.output.LayerNorm.weight tensor(764)\n",
            "bert.encoder.layer.1.output.LayerNorm.bias tensor(764)\n",
            "bert.encoder.layer.1.output.adapter.fc1.weight tensor(1529676)\n",
            "bert.encoder.layer.1.output.adapter.fc1.bias tensor(1990)\n",
            "bert.encoder.layer.1.output.adapter.fc2.weight tensor(1525625)\n",
            "bert.encoder.layer.1.output.adapter.fc2.bias tensor(764)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight tensor(765)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias tensor(765)\n",
            "bert.encoder.layer.2.attention.output.adapter.fc1.weight tensor(1527566)\n",
            "bert.encoder.layer.2.attention.output.adapter.fc1.bias tensor(1992)\n",
            "bert.encoder.layer.2.attention.output.adapter.fc2.weight tensor(1520208)\n",
            "bert.encoder.layer.2.attention.output.adapter.fc2.bias tensor(764)\n",
            "bert.encoder.layer.2.output.LayerNorm.weight tensor(766)\n",
            "bert.encoder.layer.2.output.LayerNorm.bias tensor(764)\n",
            "bert.encoder.layer.2.output.adapter.fc1.weight tensor(1528640)\n",
            "bert.encoder.layer.2.output.adapter.fc1.bias tensor(1993)\n",
            "bert.encoder.layer.2.output.adapter.fc2.weight tensor(1522066)\n",
            "bert.encoder.layer.2.output.adapter.fc2.bias tensor(765)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight tensor(767)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias tensor(759)\n",
            "bert.encoder.layer.3.attention.output.adapter.fc1.weight tensor(1524715)\n",
            "bert.encoder.layer.3.attention.output.adapter.fc1.bias tensor(1985)\n",
            "bert.encoder.layer.3.attention.output.adapter.fc2.weight tensor(1517412)\n",
            "bert.encoder.layer.3.attention.output.adapter.fc2.bias tensor(759)\n",
            "bert.encoder.layer.3.output.LayerNorm.weight tensor(763)\n",
            "bert.encoder.layer.3.output.LayerNorm.bias tensor(761)\n",
            "bert.encoder.layer.3.output.adapter.fc1.weight tensor(1525775)\n",
            "bert.encoder.layer.3.output.adapter.fc1.bias tensor(1990)\n",
            "bert.encoder.layer.3.output.adapter.fc2.weight tensor(1517563)\n",
            "bert.encoder.layer.3.output.adapter.fc2.bias tensor(761)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight tensor(765)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias tensor(757)\n",
            "bert.encoder.layer.4.attention.output.adapter.fc1.weight tensor(1520433)\n",
            "bert.encoder.layer.4.attention.output.adapter.fc1.bias tensor(1975)\n",
            "bert.encoder.layer.4.attention.output.adapter.fc2.weight tensor(1506940)\n",
            "bert.encoder.layer.4.attention.output.adapter.fc2.bias tensor(761)\n",
            "bert.encoder.layer.4.output.LayerNorm.weight tensor(761)\n",
            "bert.encoder.layer.4.output.LayerNorm.bias tensor(753)\n",
            "bert.encoder.layer.4.output.adapter.fc1.weight tensor(1523961)\n",
            "bert.encoder.layer.4.output.adapter.fc1.bias tensor(1977)\n",
            "bert.encoder.layer.4.output.adapter.fc2.weight tensor(1514059)\n",
            "bert.encoder.layer.4.output.adapter.fc2.bias tensor(753)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight tensor(763)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias tensor(753)\n",
            "bert.encoder.layer.5.attention.output.adapter.fc1.weight tensor(1521973)\n",
            "bert.encoder.layer.5.attention.output.adapter.fc1.bias tensor(1972)\n",
            "bert.encoder.layer.5.attention.output.adapter.fc2.weight tensor(1511072)\n",
            "bert.encoder.layer.5.attention.output.adapter.fc2.bias tensor(751)\n",
            "bert.encoder.layer.5.output.LayerNorm.weight tensor(758)\n",
            "bert.encoder.layer.5.output.LayerNorm.bias tensor(745)\n",
            "bert.encoder.layer.5.output.adapter.fc1.weight tensor(1519538)\n",
            "bert.encoder.layer.5.output.adapter.fc1.bias tensor(1959)\n",
            "bert.encoder.layer.5.output.adapter.fc2.weight tensor(1504636)\n",
            "bert.encoder.layer.5.output.adapter.fc2.bias tensor(751)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight tensor(759)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias tensor(738)\n",
            "bert.encoder.layer.6.attention.output.adapter.fc1.weight tensor(1513015)\n",
            "bert.encoder.layer.6.attention.output.adapter.fc1.bias tensor(1967)\n",
            "bert.encoder.layer.6.attention.output.adapter.fc2.weight tensor(1500502)\n",
            "bert.encoder.layer.6.attention.output.adapter.fc2.bias tensor(757)\n",
            "bert.encoder.layer.6.output.LayerNorm.weight tensor(751)\n",
            "bert.encoder.layer.6.output.LayerNorm.bias tensor(730)\n",
            "bert.encoder.layer.6.output.adapter.fc1.weight tensor(1515834)\n",
            "bert.encoder.layer.6.output.adapter.fc1.bias tensor(1950)\n",
            "bert.encoder.layer.6.output.adapter.fc2.weight tensor(1494158)\n",
            "bert.encoder.layer.6.output.adapter.fc2.bias tensor(747)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight tensor(745)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias tensor(733)\n",
            "bert.encoder.layer.7.attention.output.adapter.fc1.weight tensor(1498032)\n",
            "bert.encoder.layer.7.attention.output.adapter.fc1.bias tensor(1916)\n",
            "bert.encoder.layer.7.attention.output.adapter.fc2.weight tensor(1491691)\n",
            "bert.encoder.layer.7.attention.output.adapter.fc2.bias tensor(747)\n",
            "bert.encoder.layer.7.output.LayerNorm.weight tensor(723)\n",
            "bert.encoder.layer.7.output.LayerNorm.bias tensor(708)\n",
            "bert.encoder.layer.7.output.adapter.fc1.weight tensor(1486094)\n",
            "bert.encoder.layer.7.output.adapter.fc1.bias tensor(1876)\n",
            "bert.encoder.layer.7.output.adapter.fc2.weight tensor(1459123)\n",
            "bert.encoder.layer.7.output.adapter.fc2.bias tensor(721)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight tensor(686)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias tensor(662)\n",
            "bert.encoder.layer.8.attention.output.adapter.fc1.weight tensor(1437538)\n",
            "bert.encoder.layer.8.attention.output.adapter.fc1.bias tensor(1837)\n",
            "bert.encoder.layer.8.attention.output.adapter.fc2.weight tensor(1413853)\n",
            "bert.encoder.layer.8.attention.output.adapter.fc2.bias tensor(691)\n",
            "bert.encoder.layer.8.output.LayerNorm.weight tensor(660)\n",
            "bert.encoder.layer.8.output.LayerNorm.bias tensor(623)\n",
            "bert.encoder.layer.8.output.adapter.fc1.weight tensor(1397494)\n",
            "bert.encoder.layer.8.output.adapter.fc1.bias tensor(1661)\n",
            "bert.encoder.layer.8.output.adapter.fc2.weight tensor(1347725)\n",
            "bert.encoder.layer.8.output.adapter.fc2.bias tensor(653)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight tensor(514)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias tensor(506)\n",
            "bert.encoder.layer.9.attention.output.adapter.fc1.weight tensor(1144517)\n",
            "bert.encoder.layer.9.attention.output.adapter.fc1.bias tensor(1529)\n",
            "bert.encoder.layer.9.attention.output.adapter.fc2.weight tensor(1188540)\n",
            "bert.encoder.layer.9.attention.output.adapter.fc2.bias tensor(592)\n",
            "bert.encoder.layer.9.output.LayerNorm.weight tensor(460)\n",
            "bert.encoder.layer.9.output.LayerNorm.bias tensor(440)\n",
            "bert.encoder.layer.9.output.adapter.fc1.weight tensor(971042)\n",
            "bert.encoder.layer.9.output.adapter.fc1.bias tensor(1248)\n",
            "bert.encoder.layer.9.output.adapter.fc2.weight tensor(1116394)\n",
            "bert.encoder.layer.9.output.adapter.fc2.bias tensor(533)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight tensor(349)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias tensor(367)\n",
            "bert.encoder.layer.10.attention.output.adapter.fc1.weight tensor(898925)\n",
            "bert.encoder.layer.10.attention.output.adapter.fc1.bias tensor(1219)\n",
            "bert.encoder.layer.10.attention.output.adapter.fc2.weight tensor(1121550)\n",
            "bert.encoder.layer.10.attention.output.adapter.fc2.bias tensor(522)\n",
            "bert.encoder.layer.10.output.LayerNorm.weight tensor(317)\n",
            "bert.encoder.layer.10.output.LayerNorm.bias tensor(300)\n",
            "bert.encoder.layer.10.output.adapter.fc1.weight tensor(712974)\n",
            "bert.encoder.layer.10.output.adapter.fc1.bias tensor(955)\n",
            "bert.encoder.layer.10.output.adapter.fc2.weight tensor(886871)\n",
            "bert.encoder.layer.10.output.adapter.fc2.bias tensor(425)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight tensor(175)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias tensor(177)\n",
            "bert.encoder.layer.11.attention.output.adapter.fc1.weight tensor(584582)\n",
            "bert.encoder.layer.11.attention.output.adapter.fc1.bias tensor(749)\n",
            "bert.encoder.layer.11.attention.output.adapter.fc2.weight tensor(922154)\n",
            "bert.encoder.layer.11.attention.output.adapter.fc2.bias tensor(409)\n",
            "bert.encoder.layer.11.output.LayerNorm.weight tensor(127)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias tensor(127)\n",
            "bert.encoder.layer.11.output.adapter.fc1.weight tensor(349983)\n",
            "bert.encoder.layer.11.output.adapter.fc1.bias tensor(406)\n",
            "bert.encoder.layer.11.output.adapter.fc2.weight tensor(814534)\n",
            "bert.encoder.layer.11.output.adapter.fc2.bias tensor(326)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unstable ParamCount"
      ],
      "metadata": {
        "id": "bp-044iD-kAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch"
      ],
      "metadata": {
        "id": "9JkH7zDv-nY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else:\n",
        "            return super().find_class(module, name)"
      ],
      "metadata": {
        "id": "dih7B_pf-sGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME3-EWCFreeze-v2.1-IC/random'"
      ],
      "metadata": {
        "id": "l6koKEDD-upg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_counts = {}\n",
        "# for seed in [0,101,2650]:\n",
        "for seed in [0]:\n",
        "    # for rand_idx in [0,3,6]:\n",
        "    for rand_idx in [0]:\n",
        "        for m in [1,2,3,4,5]:\n",
        "            with open(path3+str(rand_idx)+'_seed'+str(seed)+'model_'+str(m)+'_instability_paramcount.pkl', 'rb') as handle:\n",
        "                # temp = torch.load(handle, map_location=torch.device('cpu'))\n",
        "                temp = CPU_Unpickler(handle).load()\n",
        "                check_counts['random'+str(rand_idx)+'seed'+str(seed)+'model'+str(m)] = temp"
      ],
      "metadata": {
        "id": "U-Fr8rEG_JxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in check_counts['random0seed0model3'].items():\n",
        "  print(k,v)\n",
        "  break"
      ],
      "metadata": {
        "id": "NMyUMdo6AwSi",
        "outputId": "d75b5a28-91af-4f25-d021-dc2ab905145a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.0.attention.output.LayerNorm.weight tensor(740)\n"
          ]
        }
      ]
    }
  ]
}
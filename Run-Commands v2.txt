-------------------------------------------------Amazon Sentiment-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-AdapterSEQ/
-----------
CTR
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-CTR/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-EWC/
-----------
EWC Norm
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.0005 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-EWCNorm/
-----------
-------------------------------------------------Amazon Sentiment Single Head-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-AdapterSEQ/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC/
-----------
-------------------------------------------------AnnoMI Behaviour-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQ/
-----------
Adapter SEQ Attributions (test wrt actual class, 5 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --save_metadata test_attributions --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQAttr/
-----------
Adapter SEQ Attributions2 (all wrt pred class, 2 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --save_metadata all --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQAttr2/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-EWC/
-----------
CTR
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-CTR/
-----------
-------------------------------------------------AnnoMI Behaviour Single Head-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-AdapterSEQ/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC/
-----------
MAS
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-MAS/
-----------
-------------------------------------------------HWU64 Intent Cla-------------------------------------------------------------
-----------
Adapter MTL (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-AdapterMTL/
-----------
Adapter SEQ (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-AdapterSEQ/
-----------
Adapter SEQ (RBS)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuRBS-AdapterSEQ/
-----------
EWC (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 500000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-EWC/
-----------
-------------------------------------------------HWU64 Intent Cla Multi Head-------------------------------------------------------------
-----------
Adapter MTL (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-AdapterMTL/
-----------
Adapter SEQ (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-AdapterSEQ/
-----------
Adapter EWC (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 2500000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-EWC/
-----------
Adapter MAS (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 2500 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS/
-----------
CTR (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-CTR/
-----------
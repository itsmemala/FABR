-------------------------------------------------Amazon Sentiment-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-AdapterSEQ/
-----------
CTR
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-CTR/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-EWC/
-----------
EWC.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 25000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-EWC.1/
-----------
EWC Norm
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.0005 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rME4-EWCNorm/
-----------
-------------------------------------------------Amazon Sentiment Single Head-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-AdapterSEQ/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC/
-----------
EWC.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 25000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC.1/
-----------
EWC.2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 50000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC.2/
-----------
EWC.3
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 100000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC.3/
-----------
EWC.5
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 75000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-EWC.5/
-----------
MAS
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.1 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-MAS/
-----------
MAS.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.25 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-MAS.1/
-----------
MAS.2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment bert_dis --subset_data 200 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/s200rSH-MAS.2/
-----------
-------------------------------------------------AnnoMI Behaviour-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQ/
-----------
Adapter SEQ Attributions (test wrt actual class, 5 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --save_metadata test_attributions --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQAttr/
-----------
Adapter SEQ Attributions2 (all wrt pred class, 2 tasks)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --save_metadata all --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-AdapterSEQAttr2/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-EWC/
-----------
CTR
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrME4-CTR/
-----------
-------------------------------------------------AnnoMI Behaviour Single Head-------------------------------------------------------------
-----------
Adapter MTL
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-AdapterMTL/
-----------
Adapter SEQ
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --train_batch_size 32 --use_cls_wgts True --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-AdapterSEQ/
-----------
EWC
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC/
-----------
EWC.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 25000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC.1/
-----------
EWC.2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 50000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC.2/
-----------
EWC.3
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 100000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC.3/
-----------
EWC.4
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 500 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC.4/
-----------
EWC.5
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 75000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-EWC.5/
-----------
MAS
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.5 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-MAS/
-----------
MAS.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.25 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-MAS.1/
-----------
MAS.2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment annomi --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario dil --use_cls_wgts True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --lamb 0.1 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/AnnoMIStrSH-MAS.2/
-----------
-------------------------------------------------HWU64 Intent Cla-------------------------------------------------------------
-----------
Adapter MTL (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-AdapterMTL/
-----------
Adapter SEQ (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-AdapterSEQ/
-----------
Adapter SEQ (RBS)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario cil --use_rbs True --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuRBS-AdapterSEQ/
-----------
EWC (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --backbone bert_adapter --baseline ewc --note random0 --idrandom 0 --seed 0 --scenario cil --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --lamb 500000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuNLR-EWC/
-----------
-------------------------------------------------HWU64 Intent Cla Multi Head-------------------------------------------------------------
-----------
Adapter MTL (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_mtl --baseline mtl --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-AdapterMTL/
-----------
Adapter SEQ (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_seq --baseline seq --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.002 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-AdapterSEQ/
-----------
Adapter EWC (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 2500000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-EWC/
-----------
Adapter EWC.1 (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 5000000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-EWC.1/
-----------
Adapter MAS (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 2500 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS/
-----------
MAS.1
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 15000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS.1/
-----------
MAS.2
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 50000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS.2/
-----------
MAS.3
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 75000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS.3/
-----------
MAS.4
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_adapter_ewc --imp function --baseline ewc --backbone bert_adapter --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --lamb 100000 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-MAS.4/
-----------
CTR (NLR)
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach ctr --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 50 --valid_loss_es 0.02 --lr_patience 5 --learning_rate 0.003 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-CTR/
-----------
KAN
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach bert_gru_kan_ncl --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 100 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-KAN/
-----------
TASKDROP
!python  FABR//run.py --bert_model 'bert-base-uncased' --experiment hwu64 --approach taskdrop --baseline None --note random0 --idrandom 0 --seed 0 --scenario til --train_batch_size 32 --num_train_epochs 100 --my_save_path /content/gdrive/MyDrive/s200_kan_myocc_attributions_lfa/hwuMH-TASKDROP/